{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelArgs(dim=128, n_layers=2, n_heads=4, n_kv_heads=2, vocab_size=-1, multiple_of=256, ffn_dim_multiplier=None, norm_eps=1e-05, max_batch_size=32, max_seq_len=128, epochs=5000)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 128 \n",
    "    n_layers: int = 2\n",
    "    n_heads: int = 4\n",
    "    n_kv_heads: Optional[int] = 2\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    ffn_dim_multiplier: Optional[float] = None\n",
    "    norm_eps: float = 1e-5\n",
    "\n",
    "    max_batch_size: int = 32\n",
    "    max_seq_len: int = 16 * 8\n",
    "\n",
    "    epochs: int = 5_000    \n",
    "\n",
    "model_config = ModelArgs()\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 1115394\n"
     ]
    }
   ],
   "source": [
    "# simple tokenization by characters\n",
    "def encode(s):\n",
    "    return [stoi[ch] for ch in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "\n",
    "lines = open('./data/Shakespeare.txt', 'r').read()\n",
    "vocab = sorted(list(set(lines)))\n",
    "itos = {i:ch for i, ch in enumerate(vocab)}\n",
    "stoi = {ch:i for i, ch in enumerate(vocab)}\n",
    "dataset = torch.tensor(encode(lines), dtype=torch.int8)\n",
    "print(f'Sentences: {dataset.shape[0]}')\n",
    "\n",
    "model_config.vocab_size = len(vocab)\n",
    "\n",
    "def get_batches(data, split, batch_size, context_window):\n",
    "    train = data[:int(.8 * len(data))]\n",
    "    val = data[int(.8 * len(data)): int(.9 * len(data))]\n",
    "    test = data[int(.9 * len(data)):]\n",
    "\n",
    "    if split == 'train':\n",
    "        batch_data = train\n",
    "    elif split == 'test':\n",
    "        batch_data = test\n",
    "    else:\n",
    "        batch_data = val\n",
    "\n",
    "    # pick random starting points\n",
    "    ix = torch.randint(0, batch_data.size(0) - context_window - 1, (batch_size,))\n",
    "    x = torch.stack([batch_data[i:i+context_window] for i in ix]).long()\n",
    "    y = torch.stack([batch_data[i+1:i+context_window+1] for i in ix]).long()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS Normalization \n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/1910.07467.pdf)\n",
    "- [Reference implementation](https://github.com/facebookresearch/llama/blob/54d44631054deae836aec8ceff92dcf8f20ca9e7/llama/model.py#L34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Initialize the RMSNorm normalization layer.\n",
    "\n",
    "        Args:\n",
    "            dim (int): The dimension of the input tensor.\n",
    "            eps (float, optional): A small value added to the denominator for numerical stability. Default is 1e-6.\n",
    "\n",
    "        Attributes:\n",
    "            eps (float): A small value added to the denominator for numerical stability.\n",
    "            weight (nn.Parameter): Learnable scaling parameter.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x : torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Apply the RMSNorm normalization to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The normalized tensor.\n",
    "\n",
    "        \"\"\"\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the RMSNorm layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor after applying RMSNorm.\n",
    "\n",
    "        \"\"\"        \n",
    "        return self._norm(x.float()).type_as(x) * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoPE\n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/2104.09864.pdf)\n",
    "- [Reference Implementation](https://github.com/facebookresearch/llama/blob/dccf644213a2771a81fc4a754eed9623ea7f8444/llama/model.py#L80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPE:\n",
    "    def __init__(self, dim: int, max_seq_len: int, theta: float = 10000.0):\n",
    "        \"\"\"\n",
    "        Precompute the frequency tensor for complex exponentials (cis, defined as 'm*theta_i' in the paper) \n",
    "        with given dimensions.\n",
    "\n",
    "        Calculates a frequency tensor with complex exponentials using the given dimension 'dim'\n",
    "        and the max sequence length. The 'theta_base' parameter scales the frequencies.\n",
    "        The returned tensor contains complex values in complex64 data type.\n",
    "\n",
    "        Args:\n",
    "            dim (int): Dimension of the frequency tensor.\n",
    "            max_seq_len (int): Max sequence length.\n",
    "            theta_base (float, optional): Scaling factor for frequency computation. Defaults to 10000.0.\n",
    "        \"\"\"\n",
    "        freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "        freqs = torch.outer(torch.arange(max_seq_len), freqs).float()\n",
    "        self.freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "        print(f'Initialized RoPE with shape {self.freqs_cis.shape}')\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor, start_pos = 0) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply rotary embeddings to input tensors using the given frequency tensor.\n",
    "\n",
    "        This function first reshapes the frequency tensor to have the same shape as the target tensor 'x'\n",
    "        for the purpose of broadcasting the frequency tensor during element-wise operations. Then, it applies \n",
    "        rotary embeddings to 'x' tensor using frequency tensor 'freqs_cis'.         \n",
    "        \"\"\"\n",
    "        x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2))\n",
    "\n",
    "        freqs_cis = self.freqs_cis[start_pos:start_pos + x.shape[-2]]\n",
    "                \n",
    "        x_real = torch.view_as_real(x_complex * freqs_cis).flatten(-2)\n",
    "        \n",
    "        return x_real.type_as(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoPE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RoPE with shape torch.Size([256, 64])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "dim = 128\n",
    "max_seq_len = 256\n",
    "\n",
    "def get_rotary_matrix(context_window, embedding_dim):\n",
    "    R = torch.zeros((context_window, embedding_dim, embedding_dim), requires_grad=False)\n",
    "    for position in range(context_window):\n",
    "        for i in range(embedding_dim//2):\n",
    "            theta = 10000. ** (-2.*i / embedding_dim)\n",
    "            m_theta = position * theta\n",
    "            R[position, 2*i,2*i] = np.cos(m_theta)\n",
    "            R[position, 2*i,2*i+1] = - np.sin(m_theta)\n",
    "            R[position, 2*i+1,2*i] = np.sin(m_theta)\n",
    "            R[position, 2*i+1,2*i+1] = np.cos(m_theta)\n",
    "    return R\n",
    "\n",
    "R = get_rotary_matrix(max_seq_len, dim)\n",
    "\n",
    "X= torch.ones(1, max_seq_len, dim)\n",
    "rope = RoPE(dim=dim, max_seq_len=max_seq_len)\n",
    "X1 = rope(X)\n",
    "X2 = (R @ X.unsqueeze(-1)).flatten(-2)\n",
    "\n",
    "print(X1.allclose(X2, atol=1e-3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Networks with SwiGLU\n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/2002.05202.pdf)\n",
    "- [Reference Implementation](https://github.com/facebookresearch/llama/blob/dccf644213a2771a81fc4a754eed9623ea7f8444/llama/model.py#L307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class FFN_SwiGLU(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            config: ModelArgs,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim (int): Input dimension.\n",
    "            hidden_dim (int): Hidden dimension of the feedforward layer.\n",
    "            multiple_of (int): Value to ensure hidden dimension is a multiple of this value.\n",
    "            ffn_dim_multiplier (float, optional): Custom multiplier for hidden dimension. Defaults to None.\n",
    "\n",
    "        Attributes:\n",
    "            w1 (ColumnParallelLinear): Linear transformation for the first layer.\n",
    "            w2 (RowParallelLinear): Linear transformation for the second layer.\n",
    "            w3 (ColumnParallelLinear): Linear transformation for the third layer.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        hidden_dim = (config.dim * 4) * 2 // 3\n",
    "        # custom dim factor multiplier\n",
    "        if config.ffn_dim_multiplier is not None:\n",
    "            hidden_dim = config.ffn_dim_multiplier * hidden_dim\n",
    "        hidden_dim = config.multiple_of * ((hidden_dim + config.multiple_of - 1) // config.multiple_of)\n",
    "\n",
    "        self.w = nn.Linear(config.dim, hidden_dim, bias=False)\n",
    "        self.v = nn.Linear(config.dim, hidden_dim, bias=False)\n",
    "        self.w_2 = nn.Linear(hidden_dim, config.dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(F.silu(self.w(x)) * self.v(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "*Note:* 2 differences with the [original Llama implementation](https://github.com/facebookresearch/llama/blob/dccf644213a2771a81fc4a754eed9623ea7f8444/llama/model.py#L176)\n",
    "- The weight matrix has 3 dimensions as: `(number_head * model_dimension * head_dimension)` instead of `(model_dimension * model_dimension)`. This is strictly follow the \"Attention is all you need\" paper\n",
    "- For Group Query Attention implmentation, instead of repeating KV values which is against the purpose of GQA (to reduce KV load overhead). Here reshapes the Q/K/V to 5 dimensions: `(batch_size * number_kv_heads * number_shared_kv (number_heads/number_kv_heads) * sequence_length * head_dimension)` and do matmut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"Multi-head attention module.\"\"\"\n",
    "\n",
    "    shared_rope : RoPE = None    \n",
    "\n",
    "    def __init__(self, config : ModelArgs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.head_dim = config.dim // config.n_heads\n",
    "        self.n_kv_heads = config.n_heads if config.n_kv_heads is None else config.n_kv_heads\n",
    "        \n",
    "        if Attention.shared_rope is None:\n",
    "            Attention.shared_rope = RoPE(self.head_dim, config.max_seq_len)\n",
    "\n",
    "        self.w_q = nn.Parameter(nn.init.kaiming_normal_(torch.empty(config.n_heads,config.dim, self.head_dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "        self.w_k = nn.Parameter(nn.init.kaiming_normal_(torch.empty(self.n_kv_heads,config.dim, self.head_dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "        self.w_v = nn.Parameter(nn.init.kaiming_normal_(torch.empty(self.n_kv_heads,config.dim, self.head_dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "        self.w_o = nn.Parameter(nn.init.kaiming_normal_(torch.empty(config.n_heads * self.head_dim, config.dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "\n",
    "        self.cache_k = torch.zeros(config.max_batch_size, config.n_kv_heads, config.max_seq_len, self.head_dim, requires_grad=False)\n",
    "        self.cache_v = torch.zeros_like(self.cache_k, requires_grad=False)\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "\n",
    "    def forward(self, x: torch.tensor, start_pos : int) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, dim)\n",
    "        q: (batch_size, n_heads, seq_len, head_dim)\n",
    "        k: (batch_size, n_heads, seq_len, head_dim)\n",
    "        v: (batch_size, n_heads, seq_len, head_dim)\n",
    "        \"\"\"\n",
    "        q = x.unsqueeze(1) @ self.w_q\n",
    "        k = x.unsqueeze(1) @ self.w_k\n",
    "        v = x.unsqueeze(1) @ self.w_v\n",
    "\n",
    "        q = Attention.shared_rope(q, start_pos)\n",
    "        k = Attention.shared_rope(k, start_pos)\n",
    "\n",
    "        if self.training:       # apply dropout only during training\n",
    "            dropout_p = 0.1            \n",
    "        else:            \n",
    "            self.cache_k[:, :, start_pos:start_pos + x.shape[-2]] = k\n",
    "            self.cache_v[:, :, start_pos:start_pos + x.shape[-2]] = v        \n",
    "            k = self.cache_k[:, :, :start_pos + x.shape[-2]]\n",
    "            v = self.cache_v[:, :, :start_pos + x.shape[-2]]\n",
    "\n",
    "            dropout_p = 0\n",
    "        \n",
    "        if x.shape[-2] == 1:    # if only one token, then not causal            \n",
    "            is_causal = False\n",
    "        else:\n",
    "            is_causal = True\n",
    "\n",
    "        # split heads and reshape Q, K, V as (batch_size, kv_heads, n_heads//kv_heads, seq_len, head_dim)\n",
    "        q = q.view(self.config.max_batch_size, self.config.n_kv_heads, -1, q.shape[-2], self.head_dim)\n",
    "        k = k.view(self.config.max_batch_size, self.config.n_kv_heads, -1, k.shape[-2], self.head_dim)\n",
    "        v = v.view(self.config.max_batch_size, self.config.n_kv_heads, -1, v.shape[-2], self.head_dim)\n",
    "        \n",
    "        o = F.scaled_dot_product_attention(q, k, v, dropout_p = dropout_p, is_causal = is_causal)\n",
    "        o = o.permute(0, 3, 1, 2, 4).contiguous().view(o.shape[0], o.shape[3], -1)       # concatenate heads\n",
    "        o = o @ self.w_o\n",
    "        o = self.dropout(o)\n",
    "\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class Llama2Block(nn.Module):\n",
    "    def __init__(self, config: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.rms = RMSNorm(config.dim)\n",
    "\n",
    "        self.attention = Attention(config)\n",
    "        self.attention_norm = RMSNorm(config.dim, eps = config.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(config.dim, eps = config.norm_eps)\n",
    "        self.ffn_swiglu = FFN_SwiGLU(config)\n",
    "\n",
    "    def forward(self, x, start_pos) -> torch.tensor:\n",
    "        x = x + self.attention(self.attention_norm(x), start_pos)\n",
    "        out = x + self.ffn_swiglu(self.ffn_norm(x))\n",
    "\n",
    "        return out\n",
    "\n",
    "class Llama2(nn.Module):\n",
    "    def __init__(self, config: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        Attention.shared_rope = None    # clear the shared rope defined in Attention class\n",
    "\n",
    "        self.config = config\n",
    "        self.embeddings = nn.Embedding(config.vocab_size, config.dim)\n",
    "        self.llama_blocks = nn.Sequential(\n",
    "            OrderedDict([(f\"LlamaBlock_{i}\", Llama2Block(config)) for i in range(config.n_layers)])\n",
    "        )\n",
    "        self.norm = RMSNorm(config.dim)\n",
    "        self.output = nn.Linear(config.dim, config.vocab_size, bias=False)\n",
    "\n",
    "        print(\"model params:\", sum([m.numel() for m in self.parameters()]))\n",
    "\n",
    "    def forward(self, idx, start_pos = 0, targets = None):\n",
    "        h = self.embeddings(idx)\n",
    "\n",
    "        for block in self.llama_blocks:\n",
    "            h = block(h, start_pos)\n",
    "\n",
    "        h = self.norm(h)\n",
    "        logits = self.output(h)\n",
    "\n",
    "        if targets is None:\n",
    "            return logits\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(-1, self.config.vocab_size), targets.view(-1))\n",
    "            return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "@torch.no_grad()  # don't compute gradients for this function\n",
    "def evaluate_loss(model:Llama2):\n",
    "    config = model.config\n",
    "    out = {}\n",
    "    is_training = model.training\n",
    "\n",
    "    if is_training:\n",
    "        model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = []\n",
    "        for _ in range(10):\n",
    "            xb, yb = get_batches(dataset, split, config.max_batch_size, config.max_seq_len)\n",
    "            _, loss = model(xb, 0, yb)\n",
    "            losses.append(loss.item())\n",
    "        out[split] = np.mean(losses)\n",
    "    if is_training:\n",
    "        model.train()\n",
    "\n",
    "    return out\n",
    "\n",
    "def train(model: Llama2, optimizer:torch.optim.Optimizer, scheduler = None, print_logs = False, log_interval = 100):\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    config = model.config\n",
    "    for epoch in range(config.epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        xs, ys = get_batches(dataset, 'train', config.max_batch_size, config.max_seq_len)\n",
    "        _, loss = model(xs, 0, ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        if epoch % log_interval == 0:\n",
    "            batch_time = time.time() - start_time\n",
    "            x = evaluate_loss(model)\n",
    "            losses += [x]\n",
    "            if print_logs:\n",
    "                print(f\"Epoch {epoch} | val loss {x['val']:.3f} | Time {batch_time:.3f} | ETA in seconds {batch_time * (config.epochs - epoch)/log_interval :.3f}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            if scheduler:\n",
    "                print(\"lr: \", scheduler.get_lr())            \n",
    "\n",
    "    print(\"validation loss: \", losses[-1]['val'])\n",
    "    return pd.DataFrame(losses).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RoPE with shape torch.Size([128, 16])\n",
      "model params: 509056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | val loss 4.211 | Time 0.097 | ETA in seconds 4.853\n",
      "Epoch 100 | val loss 2.417 | Time 6.835 | ETA in seconds 334.908\n",
      "Epoch 200 | val loss 2.171 | Time 6.744 | ETA in seconds 323.701\n",
      "Epoch 300 | val loss 2.000 | Time 6.699 | ETA in seconds 314.861\n",
      "Epoch 400 | val loss 1.925 | Time 7.208 | ETA in seconds 331.557\n",
      "Epoch 500 | val loss 1.853 | Time 8.302 | ETA in seconds 373.597\n",
      "Epoch 600 | val loss 1.811 | Time 7.963 | ETA in seconds 350.388\n",
      "Epoch 700 | val loss 1.769 | Time 8.656 | ETA in seconds 372.197\n",
      "Epoch 800 | val loss 1.727 | Time 8.682 | ETA in seconds 364.661\n",
      "Epoch 900 | val loss 1.723 | Time 8.687 | ETA in seconds 356.181\n",
      "Epoch 1000 | val loss 1.711 | Time 8.616 | ETA in seconds 344.628\n",
      "Epoch 1100 | val loss 1.680 | Time 8.680 | ETA in seconds 338.515\n",
      "Epoch 1200 | val loss 1.685 | Time 8.692 | ETA in seconds 330.313\n",
      "Epoch 1300 | val loss 1.699 | Time 8.673 | ETA in seconds 320.888\n",
      "Epoch 1400 | val loss 1.676 | Time 8.727 | ETA in seconds 314.178\n",
      "Epoch 1500 | val loss 1.656 | Time 8.796 | ETA in seconds 307.870\n",
      "Epoch 1600 | val loss 1.635 | Time 8.725 | ETA in seconds 296.649\n",
      "Epoch 1700 | val loss 1.627 | Time 8.779 | ETA in seconds 289.693\n",
      "Epoch 1800 | val loss 1.633 | Time 8.813 | ETA in seconds 282.007\n",
      "Epoch 1900 | val loss 1.638 | Time 8.926 | ETA in seconds 276.706\n",
      "Epoch 2000 | val loss 1.614 | Time 8.904 | ETA in seconds 267.128\n",
      "Epoch 2100 | val loss 1.606 | Time 8.766 | ETA in seconds 254.215\n",
      "Epoch 2200 | val loss 1.614 | Time 8.847 | ETA in seconds 247.706\n",
      "Epoch 2300 | val loss 1.612 | Time 8.891 | ETA in seconds 240.045\n",
      "Epoch 2400 | val loss 1.606 | Time 8.760 | ETA in seconds 227.768\n",
      "Epoch 2500 | val loss 1.612 | Time 8.787 | ETA in seconds 219.673\n",
      "Epoch 2600 | val loss 1.595 | Time 8.762 | ETA in seconds 210.293\n",
      "Epoch 2700 | val loss 1.604 | Time 8.684 | ETA in seconds 199.738\n",
      "Epoch 2800 | val loss 1.576 | Time 8.706 | ETA in seconds 191.536\n",
      "Epoch 2900 | val loss 1.584 | Time 8.716 | ETA in seconds 183.026\n",
      "Epoch 3000 | val loss 1.589 | Time 8.772 | ETA in seconds 175.450\n",
      "Epoch 3100 | val loss 1.593 | Time 9.229 | ETA in seconds 175.355\n",
      "Epoch 3200 | val loss 1.560 | Time 8.673 | ETA in seconds 156.109\n",
      "Epoch 3300 | val loss 1.587 | Time 8.353 | ETA in seconds 141.993\n",
      "Epoch 3400 | val loss 1.569 | Time 8.487 | ETA in seconds 135.791\n",
      "Epoch 3500 | val loss 1.559 | Time 8.428 | ETA in seconds 126.427\n",
      "Epoch 3600 | val loss 1.583 | Time 8.446 | ETA in seconds 118.241\n",
      "Epoch 3700 | val loss 1.560 | Time 8.520 | ETA in seconds 110.764\n",
      "Epoch 3800 | val loss 1.570 | Time 8.626 | ETA in seconds 103.508\n",
      "Epoch 3900 | val loss 1.567 | Time 8.647 | ETA in seconds 95.115\n",
      "Epoch 4000 | val loss 1.565 | Time 8.448 | ETA in seconds 84.477\n",
      "Epoch 4100 | val loss 1.551 | Time 8.462 | ETA in seconds 76.157\n",
      "Epoch 4200 | val loss 1.562 | Time 8.365 | ETA in seconds 66.918\n",
      "Epoch 4300 | val loss 1.561 | Time 8.513 | ETA in seconds 59.588\n",
      "Epoch 4400 | val loss 1.593 | Time 8.390 | ETA in seconds 50.338\n",
      "Epoch 4500 | val loss 1.558 | Time 8.386 | ETA in seconds 41.929\n",
      "Epoch 4600 | val loss 1.573 | Time 8.405 | ETA in seconds 33.618\n",
      "Epoch 4700 | val loss 1.544 | Time 8.294 | ETA in seconds 24.883\n",
      "Epoch 4800 | val loss 1.540 | Time 8.372 | ETA in seconds 16.744\n",
      "Epoch 4900 | val loss 1.549 | Time 8.426 | ETA in seconds 8.426\n",
      "validation loss:  1.5492457389831542\n",
      "CPU times: user 1h 14min 55s, sys: 1.52 s, total: 1h 14min 57s\n",
      "Wall time: 7min 29s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "llama = Llama2(model_config)\n",
    "optimizer = torch.optim.Adam(llama.parameters())\n",
    "train(llama, optimizer, print_logs=True)\n",
    "\n",
    "# Save\n",
    "now = datetime.now()\n",
    "model_name = f'./checkpoint/llama2_L{model_config.n_layers}xH{model_config.n_heads}xN{model_config.max_seq_len}xD{model_config.dim}_{now.year}_{now.month}_{now.day}_{now.hour}_{now.minute}.pth'\n",
    "torch.save({'model_state_dict': llama.state_dict()}, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model : Llama2, max_new_tokens = 10):\n",
    "    model.eval()\n",
    "    config = model.config\n",
    "    max_new_tokens = model.config.max_seq_len if max_new_tokens > model.config.max_seq_len else max_new_tokens\n",
    "    idx = torch.zeros(config.max_batch_size, 1).long()\n",
    "\n",
    "    start_pos = 0\n",
    "    for i in range(max_new_tokens):\n",
    "        if i == 0:\n",
    "            logits = model(idx)\n",
    "        else:\n",
    "            logits = model(idx[:, -1].unsqueeze(-1), start_pos)\n",
    "            # logits = model(idx[:, -config.max_seq_len:], 0)\n",
    "        \n",
    "        last_time_step_logits = logits[:, -1, :]            # all the batches (1), last time step, all the logits\n",
    "        p = F.softmax(last_time_step_logits, dim=-1)        # softmax to get probabilities\n",
    "        idx_next = torch.multinomial(\n",
    "            p, num_samples=1\n",
    "        )                                                   # sample from the distribution to get the next token\n",
    "\n",
    "        start_pos = idx.shape[-1]\n",
    "        idx = torch.cat([idx, idx_next], dim=-1)            # append to the sequence\n",
    "                    \n",
    "    return [decode(x) for x in idx.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RoPE with shape torch.Size([128, 16])\n",
      "model params: 509056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "## Get lastest checkpoint\n",
    "files = glob.glob('./checkpoint/*.pth')\n",
    "files.sort(key=os.path.getmtime)\n",
    "model_name = files[-1]\n",
    "\n",
    "llama_infer = Llama2(model_config)\n",
    "llama_infer.load_state_dict(torch.load(model_name)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HERMIONE:\n",
      "Is I should I he do me to be so said in hear:\n",
      "I dear die imprison-happiness know\n",
      "Exours. Go, venger; the king's my min\n",
      "\n",
      "CORIOLANUS:\n",
      "Here's the such me.\n",
      "\n",
      "RIVERS:\n",
      "From hoar.\n",
      "\n",
      "First Murderer:\n",
      "May thee to Juliet, my lord, delivers,\n",
      "And them from cover \n",
      "\n",
      "Clarence my be rison me!\n",
      "\n",
      "LUCIO:\n",
      "In Warwicks marry pride.\n",
      "\n",
      "PRINCE:\n",
      "Why, well: and their time only esolve your name it tongs\n",
      "That\n",
      "\n",
      "See hill not que't\n",
      "He this true great sorrow one are fruit:\n",
      "And that you have world in Juliet,\n",
      "Be from the unger desirest?\n",
      "\n",
      "Mess\n",
      "\n",
      "KING HENRY VI:\n",
      "Who more nor most I forth, the do a strike way is lark and,\n",
      "That witsh so at!\n",
      "\n",
      "Put were his crown: thy fancy swee\n",
      "\n",
      "Richard. This is these pent! for her debt out my words,\n",
      "Is royal and lament bone bush my greep;\n",
      "Where her I am, as what to hit b\n",
      "\n",
      "LUCIO:\n",
      "Great or golden time!\n",
      "I strives, upon the man, boy\n",
      "Son: or thy by your way.\n",
      "\n",
      "Vallouraitor of us a dreams better,\n",
      "With sig\n",
      "\n",
      "And your stand, so good festionable hurl'd in me\n",
      "Prith way lost more in, so not\n",
      "A was of contrajority.\n",
      "\n",
      "First Citizens:\n",
      "My lord,\n",
      "\n",
      "Is person, Where thou think it the crown,\n",
      "Be purpose and with displain: field confines of Rome,\n",
      "Which is the was him these to ma\n",
      "\n",
      "ERCUTIO:\n",
      "Before my tarm and succeds of it well?\n",
      "\n",
      "LADY GREY:\n",
      "My gracious Tybalt, you knows a royal resign 'Ot where?\n",
      "\n",
      "QUEEN MARGA\n",
      "\n",
      "Not senator, I again tood; and Sicilia,\n",
      "Even:\n",
      "I what uncle the just of king as your corse,\n",
      "Is i' then, and gest tobs haunt,\n",
      "As m\n",
      "\n",
      "\n",
      "GLOUCESTER:\n",
      "Romeo she is a name it at else?\n",
      "\n",
      "But her would hurebuness: letter dones,\n",
      "Is we not my consul?\n",
      "\n",
      "BENVOLIO:\n",
      "Ah,\n",
      "Aumerl\n",
      "\n",
      "ROMEO:\n",
      "O, Juliet it it is centrary: fortunate that airly\n",
      "comparance, or, 'twas me-supe of Lord Bless Warwick!\n",
      "O dignified!'\n",
      "We a\n",
      "\n",
      "\n",
      "I two knows of from the, you metic\n",
      "The aim a slew only heart. We show'd by your bring to Georges\n",
      "More year's creds are this sho\n",
      "\n",
      "I must who, only Since me well, though to Norfolk.\n",
      "\n",
      "ROMEO:\n",
      "Most Henry I play me, prophet my sorrow and live out thee dost hath k\n",
      "\n",
      "JULIET:\n",
      "He thy shame, I'll strain, and state of wrembling earth alone.\n",
      "\n",
      "LADY ANNE:\n",
      "O, tell unfect, Abatt, 'twas already.\n",
      "\n",
      "PRINCE\n",
      "\n",
      "SICINIUS:\n",
      "A very first her.\n",
      "\n",
      "MARCIUS:\n",
      "Threat himself or your sitter the gentle o' death!' 'twas be so?\n",
      "Well, let Romeo, Titus he\n",
      "\n",
      "To such, the no more; timely, if you were honourable\n",
      "As the a curse my lie love the prince:\n",
      "She witness is he boroughts! whose w\n",
      "\n",
      "SICINIUS:\n",
      "But dead mine it!\n",
      "\n",
      "CORIOLANUS:\n",
      "So hast your far water English Froth,\n",
      "I could be a-time death, noble of decrees and str\n",
      "\n",
      "As threein the draw's quickor-book!'\n",
      "Lord as to let would bear to we do in the wife?\n",
      "Whilst he, methought.\n",
      "\n",
      "MARCIUS:\n",
      "True are sh\n",
      "\n",
      "\n",
      "Thinkink this cond conqueror:\n",
      "Yet, prunes old them from the creanner but to the Camillo hazards.\n",
      "She more you where and ten per\n",
      "\n",
      "ROMEO:\n",
      "Sir, then thy means they absent: they in every\n",
      "fitter this loss with bound wish breath there of Purse.\n",
      "\n",
      "BENVOLIO:\n",
      "Why, Ma\n",
      "\n",
      "That wounds is as upon me ince cormined.\n",
      "\n",
      "RIVERS:\n",
      "And believe as for poor a snown my base.\n",
      "What any no more cause, a grave.\n",
      "\n",
      "MON\n",
      "\n",
      "and of love death my sweet knew-made, radop!\n",
      "This drea in thy disposition love--\n",
      "I thought the was ever supportatuble answer'd.\n",
      "\n",
      "\n",
      "could think I was sing of Hereford,\n",
      "O, put it is succased fellow to he into the night:\n",
      "Sir yet passion all we sorrow less\n",
      "The st\n",
      "\n",
      "DORCAS:\n",
      "And by this purpose's enemy\n",
      "As if well in their brother; a childily\n",
      "We within the great\n",
      "What! merry, a'oither the ship n\n",
      "\n",
      "But now their allow; stand the duke!'\n",
      "So murder:\n",
      "Should have\n",
      "A doubt for bid the glass 'This coronable are\n",
      "I day; no, sleep a ch\n",
      "\n",
      "And stiption\n",
      "Is you conquer for me: but you give: you think.\n",
      "\n",
      "QUEEN;\n",
      "Resire wife in they fight autward and adver heaven,\n",
      "Threefo\n",
      "\n",
      "ROMEO:\n",
      "A might, Marcam lord not sleep.\n",
      "\n",
      "DUKE OF YORK:\n",
      "And ay, but to usure of heaven,\n",
      "Have heart-bawd, my mother; fiol!\n",
      "\n",
      "GLOUCES\n",
      "\n",
      "A wout a jest, she thyself as is my soldier:\n",
      "Stand, give you, gracious with winder,\n",
      "Yet mine voices: yet not this prevent mind, \n",
      "\n",
      "HERMIONE:\n",
      "The of I say see, whereof the cause aumerle not,\n",
      "But gracious cannot consul in thy in her,\n",
      "Whose, on pray a, becond he\n",
      "\n",
      "ENurse:\n",
      "And spring not to posiden, threefence\n",
      "Withdraw I part to cheard's takest with way,\n",
      "And thou no looks yet no\n",
      "Her I come d\n",
      "CPU times: user 1.8 s, sys: 9.89 ms, total: 1.81 s\n",
      "Wall time: 192 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for s in generate(llama_infer, 128):\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-fundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
