{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelArgs(dim=128, n_layers=4, n_heads=4, n_kv_heads=2, vocab_size=-1, multiple_of=256, ffn_dim_multiplier=None, norm_eps=1e-05, max_batch_size=32, max_seq_len=128, epochs=5000)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 128\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    n_kv_heads: Optional[int] = 2\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    ffn_dim_multiplier: Optional[float] = None\n",
    "    norm_eps: float = 1e-5\n",
    "\n",
    "    max_batch_size: int = 32\n",
    "    max_seq_len: int = 16 * 8\n",
    "\n",
    "    epochs: int = 5_000    \n",
    "\n",
    "model_config = ModelArgs()\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 1115394\n"
     ]
    }
   ],
   "source": [
    "# simple tokenization by characters\n",
    "def encode(s):\n",
    "    return [stoi[ch] for ch in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "\n",
    "lines = open('./data/Shakespeare.txt', 'r').read()\n",
    "vocab = sorted(list(set(lines)))\n",
    "itos = {i:ch for i, ch in enumerate(vocab)}\n",
    "stoi = {ch:i for i, ch in enumerate(vocab)}\n",
    "dataset = torch.tensor(encode(lines), dtype=torch.int8)\n",
    "print(f'Sentences: {dataset.shape[0]}')\n",
    "\n",
    "model_config.vocab_size = len(vocab)\n",
    "\n",
    "def get_batches(data, split, batch_size, context_window):\n",
    "    train = data[:int(.8 * len(data))]\n",
    "    val = data[int(.8 * len(data)): int(.9 * len(data))]\n",
    "    test = data[int(.9 * len(data)):]\n",
    "\n",
    "    if split == 'train':\n",
    "        batch_data = train\n",
    "    elif split == 'test':\n",
    "        batch_data = test\n",
    "    else:\n",
    "        batch_data = val\n",
    "\n",
    "    # pick random starting points\n",
    "    ix = torch.randint(0, batch_data.size(0) - context_window - 1, (batch_size,))\n",
    "    x = torch.stack([batch_data[i:i+context_window] for i in ix]).long()\n",
    "    y = torch.stack([batch_data[i+1:i+context_window+1] for i in ix]).long()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS Normalization \n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/1910.07467.pdf)\n",
    "- [Reference implementation](https://github.com/facebookresearch/llama/blob/54d44631054deae836aec8ceff92dcf8f20ca9e7/llama/model.py#L34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Initialize the RMSNorm normalization layer.\n",
    "\n",
    "        Args:\n",
    "            dim (int): The dimension of the input tensor.\n",
    "            eps (float, optional): A small value added to the denominator for numerical stability. Default is 1e-6.\n",
    "\n",
    "        Attributes:\n",
    "            eps (float): A small value added to the denominator for numerical stability.\n",
    "            weight (nn.Parameter): Learnable scaling parameter.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x : torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Apply the RMSNorm normalization to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The normalized tensor.\n",
    "\n",
    "        \"\"\"\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the RMSNorm layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor after applying RMSNorm.\n",
    "\n",
    "        \"\"\"        \n",
    "        return self._norm(x.float()).type_as(x) * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoPE\n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/2104.09864.pdf)\n",
    "- [Reference Implementation](https://github.com/facebookresearch/llama/blob/dccf644213a2771a81fc4a754eed9623ea7f8444/llama/model.py#L80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPE:\n",
    "    def __init__(self, dim: int, max_seq_len: int, theta: float = 10000.0):\n",
    "        \"\"\"\n",
    "        Precompute the frequency tensor for complex exponentials (cis, defined as 'm*theta_i' in the paper) \n",
    "        with given dimensions.\n",
    "\n",
    "        Calculates a frequency tensor with complex exponentials using the given dimension 'dim'\n",
    "        and the max sequence length. The 'theta_base' parameter scales the frequencies.\n",
    "        The returned tensor contains complex values in complex64 data type.\n",
    "\n",
    "        Args:\n",
    "            dim (int): Dimension of the frequency tensor.\n",
    "            max_seq_len (int): Max sequence length.\n",
    "            theta_base (float, optional): Scaling factor for frequency computation. Defaults to 10000.0.\n",
    "        \"\"\"\n",
    "        freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "        freqs = torch.outer(torch.arange(max_seq_len), freqs).float()\n",
    "        self.freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "        print(f'Initialized RoPE with shape {self.freqs_cis.shape}')\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor, start_pos = 0) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply rotary embeddings to input tensors using the given frequency tensor.\n",
    "\n",
    "        This function first reshapes the frequency tensor to have the same shape as the target tensor 'x'\n",
    "        for the purpose of broadcasting the frequency tensor during element-wise operations. Then, it applies \n",
    "        rotary embeddings to 'x' tensor using frequency tensor 'freqs_cis'.         \n",
    "        \"\"\"\n",
    "        x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2))\n",
    "\n",
    "        freqs_cis = self.freqs_cis[start_pos:start_pos + x.shape[-2]]\n",
    "                \n",
    "        x_real = torch.view_as_real(x_complex * freqs_cis).flatten(-2)\n",
    "        \n",
    "        return x_real.type_as(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoPE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RoPE with shape torch.Size([256, 64])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "dim = 128\n",
    "max_seq_len = 256\n",
    "\n",
    "def get_rotary_matrix(context_window, embedding_dim):\n",
    "    R = torch.zeros((context_window, embedding_dim, embedding_dim), requires_grad=False)\n",
    "    for position in range(context_window):\n",
    "        for i in range(embedding_dim//2):\n",
    "            theta = 10000. ** (-2.*i / embedding_dim)\n",
    "            m_theta = position * theta\n",
    "            R[position, 2*i,2*i] = np.cos(m_theta)\n",
    "            R[position, 2*i,2*i+1] = - np.sin(m_theta)\n",
    "            R[position, 2*i+1,2*i] = np.sin(m_theta)\n",
    "            R[position, 2*i+1,2*i+1] = np.cos(m_theta)\n",
    "    return R\n",
    "\n",
    "R = get_rotary_matrix(max_seq_len, dim)\n",
    "\n",
    "X= torch.ones(1, max_seq_len, dim)\n",
    "rope = RoPE(dim=dim, max_seq_len=max_seq_len)\n",
    "X1 = rope(X)\n",
    "X2 = (R @ X.unsqueeze(-1)).flatten(-2)\n",
    "\n",
    "print(X1.allclose(X2, atol=1e-3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Networks with SwiGLU\n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/2002.05202.pdf)\n",
    "- [Reference Implementation](https://github.com/facebookresearch/llama/blob/dccf644213a2771a81fc4a754eed9623ea7f8444/llama/model.py#L307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class FFN_SwiGLU(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            config: ModelArgs,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim (int): Input dimension.\n",
    "            hidden_dim (int): Hidden dimension of the feedforward layer.\n",
    "            multiple_of (int): Value to ensure hidden dimension is a multiple of this value.\n",
    "            ffn_dim_multiplier (float, optional): Custom multiplier for hidden dimension. Defaults to None.\n",
    "\n",
    "        Attributes:\n",
    "            w1 (ColumnParallelLinear): Linear transformation for the first layer.\n",
    "            w2 (RowParallelLinear): Linear transformation for the second layer.\n",
    "            w3 (ColumnParallelLinear): Linear transformation for the third layer.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        hidden_dim = (config.dim * 4) * 2 // 3\n",
    "        # custom dim factor multiplier\n",
    "        if config.ffn_dim_multiplier is not None:\n",
    "            hidden_dim = config.ffn_dim_multiplier * hidden_dim\n",
    "        hidden_dim = config.multiple_of * ((hidden_dim + config.multiple_of - 1) // config.multiple_of)\n",
    "\n",
    "        self.w = nn.Linear(config.dim, hidden_dim, bias=False)\n",
    "        self.v = nn.Linear(config.dim, hidden_dim, bias=False)\n",
    "        self.w_2 = nn.Linear(hidden_dim, config.dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(F.silu(self.w(x)) * self.v(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "*Note:* 2 differences with the [original Llama implementation](https://github.com/facebookresearch/llama/blob/dccf644213a2771a81fc4a754eed9623ea7f8444/llama/model.py#L176)\n",
    "- The weight matrix has 3 dimensions as: `(number_head * model_dimension * head_dimension)` instead of `(model_dimension * model_dimension)`. This is strictly follow the \"Attention is all you need\" paper\n",
    "- For Group Query Attention implmentation, instead of repeating KV values which is against the purpose of GQA (to reduce KV load overhead). Here reshapes the Q/K/V to 5 dimensions: `(batch_size * number_kv_heads * number_shared_kv (number_heads/number_kv_heads) * sequence_length * head_dimension)` and do matmut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"Multi-head attention module.\"\"\"\n",
    "\n",
    "    shared_rope : RoPE = None    \n",
    "\n",
    "    def __init__(self, config : ModelArgs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.head_dim = config.dim // config.n_heads\n",
    "        self.n_kv_heads = config.n_heads if config.n_kv_heads is None else config.n_kv_heads\n",
    "        \n",
    "        if Attention.shared_rope is None:\n",
    "            Attention.shared_rope = RoPE(self.head_dim, config.max_seq_len)\n",
    "\n",
    "        self.w_q = nn.Parameter(nn.init.kaiming_normal_(torch.empty(config.n_heads,config.dim, self.head_dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "        self.w_k = nn.Parameter(nn.init.kaiming_normal_(torch.empty(self.n_kv_heads,config.dim, self.head_dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "        self.w_v = nn.Parameter(nn.init.kaiming_normal_(torch.empty(self.n_kv_heads,config.dim, self.head_dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "        self.w_o = nn.Parameter(nn.init.kaiming_normal_(torch.empty(config.n_heads * self.head_dim, config.dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "\n",
    "        self.cache_k = torch.zeros(config.max_batch_size, config.n_kv_heads, config.max_seq_len, self.head_dim, requires_grad=False)\n",
    "        self.cache_v = torch.zeros_like(self.cache_k, requires_grad=False)\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "\n",
    "    def forward(self, x: torch.tensor, start_pos : int) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, dim)\n",
    "        q: (batch_size, n_heads, seq_len, head_dim)\n",
    "        k: (batch_size, n_heads, seq_len, head_dim)\n",
    "        v: (batch_size, n_heads, seq_len, head_dim)\n",
    "        \"\"\"\n",
    "        q = x.unsqueeze(1) @ self.w_q\n",
    "        k = x.unsqueeze(1) @ self.w_k\n",
    "        v = x.unsqueeze(1) @ self.w_v\n",
    "\n",
    "        q = Attention.shared_rope(q, start_pos)\n",
    "        k = Attention.shared_rope(k, start_pos)\n",
    "\n",
    "        if self.training:       # apply dropout only during training\n",
    "            dropout_p = 0.1            \n",
    "        else:            \n",
    "            self.cache_k[:, :, start_pos:start_pos + x.shape[-2]] = k\n",
    "            self.cache_v[:, :, start_pos:start_pos + x.shape[-2]] = v        \n",
    "            k = self.cache_k[:, :, :start_pos + x.shape[-2]]\n",
    "            v = self.cache_v[:, :, :start_pos + x.shape[-2]]\n",
    "\n",
    "            dropout_p = 0\n",
    "        \n",
    "        if x.shape[-2] == 1:    # if only one token, then not causal            \n",
    "            is_causal = False\n",
    "        else:\n",
    "            is_causal = True\n",
    "\n",
    "        # split heads and reshape Q, K, V as (batch_size, kv_heads, n_heads//kv_heads, seq_len, head_dim)\n",
    "        q = q.view(self.config.max_batch_size, self.config.n_kv_heads, -1, q.shape[-2], self.head_dim)\n",
    "        k = k.view(self.config.max_batch_size, self.config.n_kv_heads, -1, k.shape[-2], self.head_dim)\n",
    "        v = v.view(self.config.max_batch_size, self.config.n_kv_heads, -1, v.shape[-2], self.head_dim)\n",
    "        \n",
    "        o = F.scaled_dot_product_attention(q, k, v, dropout_p = dropout_p, is_causal = is_causal)\n",
    "        o = o.permute(0, 3, 1, 2, 4).contiguous().view(o.shape[0], o.shape[3], -1)       # concatenate heads\n",
    "        o = o @ self.w_o\n",
    "        o = self.dropout(o)\n",
    "\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class Llama2Block(nn.Module):\n",
    "    def __init__(self, config: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.rms = RMSNorm(config.dim)\n",
    "\n",
    "        self.attention = Attention(config)\n",
    "        self.attention_norm = RMSNorm(config.dim, eps = config.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(config.dim, eps = config.norm_eps)\n",
    "        self.ffn_swiglu = FFN_SwiGLU(config)\n",
    "\n",
    "    def forward(self, x, start_pos) -> torch.tensor:\n",
    "        x = x + self.attention(self.attention_norm(x), start_pos)\n",
    "        out = x + self.ffn_swiglu(self.ffn_norm(x))\n",
    "\n",
    "        return out\n",
    "\n",
    "class Llama2(nn.Module):\n",
    "    def __init__(self, config: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        Attention.shared_rope = None    # clear the shared rope defined in Attention class\n",
    "\n",
    "        self.config = config\n",
    "        self.embeddings = nn.Embedding(config.vocab_size, config.dim)\n",
    "        self.llama_blocks = nn.Sequential(\n",
    "            OrderedDict([(f\"LlamaBlock_{i}\", Llama2Block(config)) for i in range(config.n_layers)])\n",
    "        )\n",
    "        self.norm = RMSNorm(config.dim)\n",
    "        self.output = nn.Linear(config.dim, config.vocab_size, bias=False)\n",
    "\n",
    "        print(\"model params:\", sum([m.numel() for m in self.parameters()]))\n",
    "\n",
    "    def forward(self, idx, start_pos = 0, targets = None):\n",
    "        h = self.embeddings(idx)\n",
    "\n",
    "        for block in self.llama_blocks:\n",
    "            h = block(h, start_pos)\n",
    "\n",
    "        h = self.norm(h)\n",
    "        logits = self.output(h)\n",
    "\n",
    "        if targets is None:\n",
    "            return logits\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(-1, self.config.vocab_size), targets.view(-1))\n",
    "            return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "@torch.no_grad()  # don't compute gradients for this function\n",
    "def evaluate_loss(model:Llama2):\n",
    "    config = model.config\n",
    "    out = {}\n",
    "    is_training = model.training\n",
    "\n",
    "    if is_training:\n",
    "        model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = []\n",
    "        for _ in range(10):\n",
    "            xb, yb = get_batches(dataset, split, config.max_batch_size, config.max_seq_len)\n",
    "            _, loss = model(xb, 0, yb)\n",
    "            losses.append(loss.item())\n",
    "        out[split] = np.mean(losses)\n",
    "    if is_training:\n",
    "        model.train()\n",
    "\n",
    "    return out\n",
    "\n",
    "def train(model: Llama2, optimizer:torch.optim.Optimizer, scheduler = None, print_logs = False, log_interval = 100):\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    config = model.config\n",
    "    for epoch in range(config.epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        xs, ys = get_batches(dataset, 'train', config.max_batch_size, config.max_seq_len)\n",
    "        _, loss = model(xs, 0, ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        if epoch % log_interval == 0:\n",
    "            batch_time = time.time() - start_time\n",
    "            x = evaluate_loss(model)\n",
    "            losses += [x]\n",
    "            if print_logs:\n",
    "                print(f\"Epoch {epoch} | val loss {x['val']:.3f} | Time {batch_time:.3f} | ETA in seconds {batch_time * (config.epochs - epoch)/log_interval :.3f}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            if scheduler:\n",
    "                print(\"lr: \", scheduler.get_lr())            \n",
    "\n",
    "    print(\"validation loss: \", losses[-1]['val'])\n",
    "    pd.DataFrame(losses).plot()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RoPE with shape torch.Size([128, 16])\n",
      "model params: 1001344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | val loss 4.037 | Time 0.275 | ETA in seconds 13.752\n",
      "Epoch 100 | val loss 2.419 | Time 14.681 | ETA in seconds 719.361\n",
      "Epoch 200 | val loss 2.126 | Time 16.256 | ETA in seconds 780.292\n",
      "Epoch 300 | val loss 1.954 | Time 16.983 | ETA in seconds 798.183\n",
      "Epoch 400 | val loss 1.852 | Time 17.979 | ETA in seconds 827.011\n",
      "Epoch 500 | val loss 1.792 | Time 18.148 | ETA in seconds 816.664\n",
      "Epoch 600 | val loss 1.733 | Time 18.070 | ETA in seconds 795.079\n",
      "Epoch 700 | val loss 1.698 | Time 18.497 | ETA in seconds 795.368\n",
      "Epoch 800 | val loss 1.693 | Time 18.416 | ETA in seconds 773.456\n",
      "Epoch 900 | val loss 1.648 | Time 18.731 | ETA in seconds 767.961\n",
      "Epoch 1000 | val loss 1.642 | Time 18.020 | ETA in seconds 720.782\n",
      "Epoch 1100 | val loss 1.627 | Time 18.133 | ETA in seconds 707.172\n",
      "Epoch 1200 | val loss 1.623 | Time 19.219 | ETA in seconds 730.341\n",
      "Epoch 1300 | val loss 1.603 | Time 18.140 | ETA in seconds 671.181\n",
      "Epoch 1400 | val loss 1.604 | Time 18.175 | ETA in seconds 654.317\n",
      "Epoch 1500 | val loss 1.558 | Time 19.372 | ETA in seconds 678.006\n",
      "Epoch 1600 | val loss 1.558 | Time 20.480 | ETA in seconds 696.316\n",
      "Epoch 1700 | val loss 1.564 | Time 18.305 | ETA in seconds 604.070\n",
      "Epoch 1800 | val loss 1.544 | Time 18.721 | ETA in seconds 599.066\n",
      "Epoch 1900 | val loss 1.540 | Time 20.860 | ETA in seconds 646.661\n",
      "Epoch 2000 | val loss 1.554 | Time 18.105 | ETA in seconds 543.147\n",
      "Epoch 2100 | val loss 1.551 | Time 18.286 | ETA in seconds 530.303\n",
      "Epoch 2200 | val loss 1.535 | Time 18.863 | ETA in seconds 528.164\n",
      "Epoch 2300 | val loss 1.505 | Time 19.186 | ETA in seconds 518.010\n",
      "Epoch 2400 | val loss 1.504 | Time 20.117 | ETA in seconds 523.043\n",
      "Epoch 2500 | val loss 1.493 | Time 19.183 | ETA in seconds 479.581\n",
      "Epoch 2600 | val loss 1.502 | Time 18.940 | ETA in seconds 454.549\n",
      "Epoch 2700 | val loss 1.483 | Time 17.767 | ETA in seconds 408.642\n",
      "Epoch 2800 | val loss 1.477 | Time 17.362 | ETA in seconds 381.961\n",
      "Epoch 2900 | val loss 1.512 | Time 17.695 | ETA in seconds 371.593\n",
      "Epoch 3000 | val loss 1.492 | Time 17.629 | ETA in seconds 352.579\n",
      "Epoch 3100 | val loss 1.486 | Time 17.428 | ETA in seconds 331.124\n",
      "Epoch 3200 | val loss 1.471 | Time 18.012 | ETA in seconds 324.224\n",
      "Epoch 3300 | val loss 1.515 | Time 21.566 | ETA in seconds 366.630\n",
      "Epoch 3400 | val loss 1.462 | Time 21.009 | ETA in seconds 336.152\n",
      "Epoch 3500 | val loss 1.461 | Time 19.977 | ETA in seconds 299.656\n",
      "Epoch 3600 | val loss 1.493 | Time 19.191 | ETA in seconds 268.677\n",
      "Epoch 3700 | val loss 1.487 | Time 17.158 | ETA in seconds 223.053\n",
      "Epoch 3800 | val loss 1.471 | Time 17.461 | ETA in seconds 209.527\n",
      "Epoch 3900 | val loss 1.456 | Time 18.104 | ETA in seconds 199.141\n",
      "Epoch 4000 | val loss 1.465 | Time 20.397 | ETA in seconds 203.968\n",
      "Epoch 4100 | val loss 1.464 | Time 18.859 | ETA in seconds 169.733\n",
      "Epoch 4200 | val loss 1.483 | Time 18.605 | ETA in seconds 148.840\n",
      "Epoch 4300 | val loss 1.474 | Time 19.400 | ETA in seconds 135.800\n",
      "Epoch 4400 | val loss 1.482 | Time 19.939 | ETA in seconds 119.637\n",
      "Epoch 4500 | val loss 1.474 | Time 18.705 | ETA in seconds 93.524\n",
      "Epoch 4600 | val loss 1.490 | Time 17.197 | ETA in seconds 68.787\n",
      "Epoch 4700 | val loss 1.462 | Time 18.296 | ETA in seconds 54.888\n",
      "Epoch 4800 | val loss 1.497 | Time 18.170 | ETA in seconds 36.339\n",
      "Epoch 4900 | val loss 1.492 | Time 18.008 | ETA in seconds 18.008\n",
      "validation loss:  1.491673219203949\n",
      "CPU times: user 2h 43min 36s, sys: 3.68 s, total: 2h 43min 40s\n",
      "Wall time: 16min 22s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "llama = Llama2(model_config)\n",
    "optimizer = torch.optim.Adam(llama.parameters())\n",
    "losses = train(llama, optimizer, print_logs=True)\n",
    "\n",
    "\n",
    "# Save\n",
    "now = datetime.now()\n",
    "model_name = f'./checkpoint/llama2_L{model_config.n_layers}xH{model_config.n_heads}xN{model_config.max_seq_len}xD{model_config.dim}_({losses[-1][\"val\"]:.3f})_{now.year}_{now.month}_{now.day}_{now.hour}_{now.minute}.pth'\n",
    "torch.save({'model_state_dict': llama.state_dict()}, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model : Llama2, max_new_tokens = 10):\n",
    "    model.eval()\n",
    "    config = model.config\n",
    "    max_new_tokens = model.config.max_seq_len if max_new_tokens > model.config.max_seq_len else max_new_tokens\n",
    "    idx = torch.zeros(config.max_batch_size, 1).long()\n",
    "\n",
    "    start_pos = 0\n",
    "    for i in range(max_new_tokens):\n",
    "        if i == 0:\n",
    "            logits = model(idx)\n",
    "        else:\n",
    "            logits = model(idx[:, -1].unsqueeze(-1), start_pos)\n",
    "            # logits = model(idx[:, -config.max_seq_len:], 0)\n",
    "        \n",
    "        last_time_step_logits = logits[:, -1, :]            # all the batches (1), last time step, all the logits\n",
    "        p = F.softmax(last_time_step_logits, dim=-1)        # softmax to get probabilities\n",
    "        idx_next = torch.multinomial(\n",
    "            p, num_samples=1\n",
    "        )                                                   # sample from the distribution to get the next token\n",
    "\n",
    "        start_pos = idx.shape[-1]\n",
    "        idx = torch.cat([idx, idx_next], dim=-1)            # append to the sequence\n",
    "                    \n",
    "    return [decode(x) for x in idx.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./checkpoint/llama2_L4xH4xN128xD128_(1.492)_2023_11_17_15_51.pth\n",
      "Initialized RoPE with shape torch.Size([128, 16])\n",
      "model params: 1001344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "## Get lastest checkpoint\n",
    "files = glob.glob('./checkpoint/*.pth')\n",
    "files.sort(key=os.path.getmtime)\n",
    "model_name = files[-1]\n",
    "print(f'Loading {model_name}')\n",
    "\n",
    "llama_infer = Llama2(model_config)\n",
    "llama_infer.load_state_dict(torch.load(model_name)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CORIOLANUS:\n",
      "Wefze, so witning; I will not speak uponer. What, is your\n",
      "called against my book with thee to last, and point:\n",
      "And w\n",
      "\n",
      "Clout, and forfeit for way; where aught\n",
      "The shrung I sunders from him, our niederer!\n",
      "And, all the tongue is matters: know, God, \n",
      "\n",
      "And which so. fought!\n",
      "\n",
      "BENVOLIO:\n",
      "Nay, naught!\n",
      "\n",
      "SICINIUS:\n",
      "I may believe your news with serve me that and large\n",
      "Look on the palema\n",
      "\n",
      "\n",
      "HERMIONE:\n",
      "ARCHat Edward are no sleep'st for fair people.\n",
      "\n",
      "CLIFFORD:\n",
      "And take you am had of your necks.\n",
      "Go, my forerest of my br\n",
      "\n",
      "I do show and with the end, and felly news\n",
      "Enclaimed by that hit with the traitors:\n",
      "\n",
      "I may come do an hour senators, do the braw\n",
      "\n",
      "Whose sworn, and not not to horse;\n",
      "For, I hope hold me and these next-wans' wish;\n",
      "Lest to dangenet with sacrel of such,\n",
      "And like\n",
      "\n",
      "GLOUCESTER:\n",
      "I will be knees in the head the gold rest, for\n",
      "whose word as the centracts of two friends of joy\n",
      "England, bed put me\n",
      "\n",
      "Doth vether with 'sis a barely?\n",
      "\n",
      "RATCLIFF:\n",
      "If to destroy but I do live you are no crown,\n",
      "Hath twain its takes me slaving mine.\n",
      "\n",
      "\n",
      "\n",
      "GLOUCESTER:\n",
      "What were is George doth now should not? lo;\n",
      "My minute and mighty love a painted us absiate;\n",
      "And his word to the one\n",
      "\n",
      "\n",
      "Shamore than all speak himick it\n",
      "That may I should say to the world morrown of doom\n",
      "From the proud friends if you with pity:\n",
      "An\n",
      "\n",
      "Nay persuade a consentence being Oxford\n",
      "Do weep for the cries of cheering hooping tale;\n",
      "Proud, this from son with amend for sigh\n",
      "\n",
      "LADY ANNE:\n",
      "Madam of grace\n",
      "Than bright not yet grief,\n",
      "I thank your County: but Warwick and your news\n",
      "Howl think the crown marquer\n",
      "\n",
      "That he do by the son\n",
      "Lain to a betil mine eyes after of the bick,\n",
      "And savage to give him half have no gifts: and, doubt not\n",
      "met\n",
      "\n",
      "\n",
      "I take my subjects' office, till have you told the soil,\n",
      "Younger the day and every well-given him.\n",
      "\n",
      "ANTIGONUS:\n",
      "What do I wish't\n",
      "\n",
      "\n",
      "Volsces for be slain; but know, you call them fell;\n",
      "And though their with our hoping, which name?\n",
      "\n",
      "YORK:\n",
      "And 'twas and quish:\n",
      "S\n",
      "\n",
      "MARCIUS:\n",
      "He, beseem, marry, must I do say you came, nones,\n",
      "It and for sake, what art a nurself.\n",
      "A short pay there, noble king fo\n",
      "\n",
      "It is thoughters of counsel of their frosom;\n",
      "Express of beholding and night, so dozen.\n",
      "I hear, more oppose: we known be no lette\n",
      "\n",
      "LEONTES:\n",
      "The slaughter? and of thy harms there.\n",
      "\n",
      "YORK:\n",
      "God last do men, that's our bratis; but beats,\n",
      "The heapest dainty foun th\n",
      "\n",
      "This place calmet of Perford, deturn'd in the best,\n",
      "With the emplous. A priest, and success language. But, you\n",
      "do more hath brav\n",
      "\n",
      "And I think to your lords prevail to give him dies,\n",
      "And give me friends of his moved-for nature.\n",
      "Ay, come my undertake me second\n",
      "\n",
      "Welcome, bie more.\n",
      "\n",
      "First Senator:\n",
      "Believe my sovereign.\n",
      "\n",
      "ROMEO:\n",
      "Ay, there I love utter them dare to be lend King!\n",
      "Come, good, t\n",
      "\n",
      "Both that till the party poor prey mind;\n",
      "And, true's pleasure still an times, which lost\n",
      "A ginners, lombialing shore over the la\n",
      "\n",
      "And moved a man't, for skill of speeds in not.\n",
      "Lady this is not flowers control, from braws;\n",
      "Against the ears will marsh\n",
      "Before \n",
      "\n",
      "\n",
      "And they were first extreme and your country maid,\n",
      "His blood shall receipt them proMistingues' low-hap.\n",
      "\n",
      "First Watchment:\n",
      "Go, n\n",
      "\n",
      "CAPULET:\n",
      "Nay, and little knee't.\n",
      "\n",
      "CORIOLANUS:\n",
      "Ha! I cannot for the tongue,\n",
      "In patiend-shop blood 'Constant and blood\n",
      "What fondly\n",
      "\n",
      "JAULIET:\n",
      "What housest will I prooF Senator: more as thou art all.\n",
      "This is their queen, was put heart my knay;\n",
      "Or, I can request \n",
      "\n",
      "JULIET:\n",
      "You are bid thee, Messenger: you have satisfied,\n",
      "Of my life I do goddest from their treason's in his\n",
      "rack winter'd mounc\n",
      "\n",
      "with an a mean; for therefore, they are under\n",
      "fected thee, are with his doles tears distincing\n",
      "caughting honour as we may all mo\n",
      "\n",
      "GLOUCESTER:\n",
      "Even ague to France; for: a sward this disgrace,\n",
      "Unto your lady worthy temples and need,\n",
      "Take them talked the\n",
      "Glouce\n",
      "\n",
      "I wisdom like whereiter, I\n",
      "sand thus with fair must: but in a true presently,\n",
      "And there in his enjoyering great were doubled,\n",
      "Wh\n",
      "\n",
      "Clouders in pretty ears remained\n",
      "This chief poison whose stood,\n",
      "O lurk have ever, and this body for a whit,\n",
      "At got and men, sway\n",
      "\n",
      "Be case the imprain of thy off rest? now\n",
      "comes a wivers. You shall do.\n",
      "\n",
      "MENENIUS:\n",
      "Accuse, my lord I mistress\n",
      "Appare your mind hi\n",
      "CPU times: user 4.99 s, sys: 9.75 ms, total: 5 s\n",
      "Wall time: 502 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for s in generate(llama_infer, 128):\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-fundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
