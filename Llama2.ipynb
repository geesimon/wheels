{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelArgs(dim=128, n_layers=2, n_heads=4, n_kv_heads=4, vocab_size=-1, multiple_of=256, ffn_dim_multiplier=None, norm_eps=1e-05, max_batch_size=32, max_seq_len=128, epochs=5000)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 128\n",
    "    n_layers: int = 2\n",
    "    n_heads: int = 4\n",
    "    n_kv_heads: Optional[int] = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    ffn_dim_multiplier: Optional[float] = None\n",
    "    norm_eps: float = 1e-5\n",
    "\n",
    "    max_batch_size: int = 32\n",
    "    max_seq_len: int = 16 * 8\n",
    "\n",
    "    epochs: int = 5_000    \n",
    "\n",
    "model_config = ModelArgs()\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 1115394\n"
     ]
    }
   ],
   "source": [
    "# simple tokenization by characters\n",
    "def encode(s):\n",
    "    return [stoi[ch] for ch in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "\n",
    "lines = open('./data/Shakespeare.txt', 'r').read()\n",
    "vocab = sorted(list(set(lines)))\n",
    "itos = {i:ch for i, ch in enumerate(vocab)}\n",
    "stoi = {ch:i for i, ch in enumerate(vocab)}\n",
    "dataset = torch.tensor(encode(lines), dtype=torch.int8)\n",
    "print(f'Sentences: {dataset.shape[0]}')\n",
    "\n",
    "model_config.vocab_size = len(vocab)\n",
    "\n",
    "def get_batches(data, split, batch_size, context_window):\n",
    "    train = data[:int(.8 * len(data))]\n",
    "    val = data[int(.8 * len(data)): int(.9 * len(data))]\n",
    "    test = data[int(.9 * len(data)):]\n",
    "\n",
    "    if split == 'train':\n",
    "        batch_data = train\n",
    "    elif split == 'test':\n",
    "        batch_data = test\n",
    "    else:\n",
    "        batch_data = val\n",
    "\n",
    "    # pick random starting points\n",
    "    ix = torch.randint(0, batch_data.size(0) - context_window - 1, (batch_size,))\n",
    "    x = torch.stack([batch_data[i:i+context_window] for i in ix]).long()\n",
    "    y = torch.stack([batch_data[i+1:i+context_window+1] for i in ix]).long()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS Normalization \n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/1910.07467.pdf)\n",
    "- [Reference implementation](https://github.com/facebookresearch/llama/blob/54d44631054deae836aec8ceff92dcf8f20ca9e7/llama/model.py#L34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Initialize the RMSNorm normalization layer.\n",
    "\n",
    "        Args:\n",
    "            dim (int): The dimension of the input tensor.\n",
    "            eps (float, optional): A small value added to the denominator for numerical stability. Default is 1e-6.\n",
    "\n",
    "        Attributes:\n",
    "            eps (float): A small value added to the denominator for numerical stability.\n",
    "            weight (nn.Parameter): Learnable scaling parameter.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x : torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Apply the RMSNorm normalization to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The normalized tensor.\n",
    "\n",
    "        \"\"\"\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the RMSNorm layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor after applying RMSNorm.\n",
    "\n",
    "        \"\"\"        \n",
    "        return self._norm(x.float()).type_as(x) * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoPE\n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/2104.09864.pdf)\n",
    "- [Reference Implementation](https://github.com/facebookresearch/llama/blob/dccf644213a2771a81fc4a754eed9623ea7f8444/llama/model.py#L80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPE:\n",
    "    def __init__(self, dim: int, max_seq_len: int, theta: float = 10000.0):\n",
    "        \"\"\"\n",
    "        Precompute the frequency tensor for complex exponentials (cis, defined as 'm*theta_i' in the paper) \n",
    "        with given dimensions.\n",
    "\n",
    "        Calculates a frequency tensor with complex exponentials using the given dimension 'dim'\n",
    "        and the max sequence length. The 'theta_base' parameter scales the frequencies.\n",
    "        The returned tensor contains complex values in complex64 data type.\n",
    "\n",
    "        Args:\n",
    "            dim (int): Dimension of the frequency tensor.\n",
    "            max_seq_len (int): Max sequence length.\n",
    "            theta_base (float, optional): Scaling factor for frequency computation. Defaults to 10000.0.\n",
    "        \"\"\"\n",
    "        freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "        freqs = torch.outer(torch.arange(max_seq_len), freqs).float()\n",
    "        self.freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "        print(f'Initialized RoPE with shape {self.freqs_cis.shape}')\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor, start_pos = 0) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply rotary embeddings to input tensors using the given frequency tensor.\n",
    "\n",
    "        This function first reshapes the frequency tensor to have the same shape as the target tensor 'x'\n",
    "        for the purpose of broadcasting the frequency tensor during element-wise operations. Then, it applies \n",
    "        rotary embeddings to 'x' tensor using frequency tensor 'freqs_cis'.         \n",
    "        \"\"\"\n",
    "        x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2))\n",
    "\n",
    "        freqs_cis = self.freqs_cis[start_pos:start_pos + x.shape[-2]]\n",
    "                \n",
    "        x_real = torch.view_as_real(x_complex * freqs_cis).flatten(-2)\n",
    "        \n",
    "        return x_real.type_as(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoPE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RoPE with shape torch.Size([256, 64])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "dim = 128\n",
    "max_seq_len = 256\n",
    "\n",
    "def get_rotary_matrix(context_window, embedding_dim):\n",
    "    R = torch.zeros((context_window, embedding_dim, embedding_dim), requires_grad=False)\n",
    "    for position in range(context_window):\n",
    "        for i in range(embedding_dim//2):\n",
    "            theta = 10000. ** (-2.*i / embedding_dim)\n",
    "            m_theta = position * theta\n",
    "            R[position, 2*i,2*i] = np.cos(m_theta)\n",
    "            R[position, 2*i,2*i+1] = - np.sin(m_theta)\n",
    "            R[position, 2*i+1,2*i] = np.sin(m_theta)\n",
    "            R[position, 2*i+1,2*i+1] = np.cos(m_theta)\n",
    "    return R\n",
    "\n",
    "R = get_rotary_matrix(max_seq_len, dim)\n",
    "\n",
    "X= torch.ones(1, max_seq_len, dim)\n",
    "rope = RoPE(dim=dim, max_seq_len=max_seq_len)\n",
    "X1 = rope(X)\n",
    "X2 = (R @ X.unsqueeze(-1)).flatten(-2)\n",
    "\n",
    "print(X1.allclose(X2, atol=1e-3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Networks with SwiGLU\n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/2002.05202.pdf)\n",
    "- [Reference Implementation](https://github.com/facebookresearch/llama/blob/dccf644213a2771a81fc4a754eed9623ea7f8444/llama/model.py#L307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class FFN_SwiGLU(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            config: ModelArgs,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim (int): Input dimension.\n",
    "            hidden_dim (int): Hidden dimension of the feedforward layer.\n",
    "            multiple_of (int): Value to ensure hidden dimension is a multiple of this value.\n",
    "            ffn_dim_multiplier (float, optional): Custom multiplier for hidden dimension. Defaults to None.\n",
    "\n",
    "        Attributes:\n",
    "            w1 (ColumnParallelLinear): Linear transformation for the first layer.\n",
    "            w2 (RowParallelLinear): Linear transformation for the second layer.\n",
    "            w3 (ColumnParallelLinear): Linear transformation for the third layer.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        hidden_dim = (config.dim * 4) * 2 // 3\n",
    "        # custom dim factor multiplier\n",
    "        if config.ffn_dim_multiplier is not None:\n",
    "            hidden_dim = config.ffn_dim_multiplier * hidden_dim\n",
    "        hidden_dim = config.multiple_of * ((hidden_dim + config.multiple_of - 1) // config.multiple_of)\n",
    "\n",
    "        self.w = nn.Linear(config.dim, hidden_dim, bias=False)\n",
    "        self.v = nn.Linear(config.dim, hidden_dim, bias=False)\n",
    "        self.w_2 = nn.Linear(hidden_dim, config.dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(F.silu(self.w(x)) * self.v(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "*Note:* 2 differences with [original Llama implementation](https://github.com/facebookresearch/llama/blob/dccf644213a2771a81fc4a754eed9623ea7f8444/llama/model.py#L176)\n",
    "- The weight matrix has 3 dimensions as: `number_head * model_dimension * head_dimension` instead of `model_dimension * model_dimension`. This is strictly follow the \"Attention is all you need\" paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 128, 128]) torch.Size([4, 128, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 128, 32])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = nn.Parameter(nn.init.kaiming_normal_(torch.empty(model_config.n_heads,model_config.dim, model_config.dim // model_config.n_heads),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "x = torch.randn(model_config.max_batch_size,model_config.max_seq_len, model_config.dim)\n",
    "print(x.unsqueeze(1).shape, w.shape)\n",
    "(x.unsqueeze(1) @ w).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"Multi-head attention module.\"\"\"\n",
    "\n",
    "    shared_rope : RoPE = None    \n",
    "\n",
    "    def __init__(self, config : ModelArgs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.head_dim = config.dim // config.n_heads\n",
    "        if Attention.shared_rope is None:\n",
    "            Attention.shared_rope = RoPE(self.head_dim, config.max_seq_len)\n",
    "\n",
    "        self.w_q = nn.Parameter(nn.init.kaiming_normal_(torch.empty(config.n_heads,config.dim, self.head_dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "        self.w_k = nn.Parameter(nn.init.kaiming_normal_(torch.empty(config.n_heads,config.dim, self.head_dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "        self.w_v = nn.Parameter(nn.init.kaiming_normal_(torch.empty(config.n_heads,config.dim, self.head_dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "        self.w_o = nn.Parameter(nn.init.kaiming_normal_(torch.empty(config.n_heads* self.head_dim, config.dim),\n",
    "                                                        mode='fan_out', nonlinearity='relu'))\n",
    "\n",
    "        self.cache_k = torch.zeros(config.max_batch_size, config.n_kv_heads, config.max_seq_len, self.head_dim, requires_grad=False)\n",
    "        self.cache_v = torch.zeros_like(self.cache_k, requires_grad=False)\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "\n",
    "    def forward(self, x: torch.tensor, start_pos : int) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, dim)\n",
    "        q: (batch_size, n_heads, seq_len, head_dim)\n",
    "        k: (batch_size, n_heads, seq_len, head_dim)\n",
    "        v: (batch_size, n_heads, seq_len, head_dim)\n",
    "        \"\"\"\n",
    "        q = x.unsqueeze(1) @ self.w_q\n",
    "        k = x.unsqueeze(1) @ self.w_k\n",
    "        v = x.unsqueeze(1) @ self.w_v\n",
    "\n",
    "        q = Attention.shared_rope(q, start_pos)\n",
    "        k = Attention.shared_rope(k, start_pos)\n",
    "\n",
    "        if self.training:       # apply dropout only during training\n",
    "            dropout_p = 0.1            \n",
    "        else:            \n",
    "            self.cache_k[:, :, start_pos:start_pos + x.shape[-2]] = k\n",
    "            self.cache_v[:, :, start_pos:start_pos + x.shape[-2]] = v        \n",
    "            k = self.cache_k[:, :, :start_pos + x.shape[-2]]\n",
    "            v = self.cache_v[:, :, :start_pos + x.shape[-2]]\n",
    "\n",
    "            dropout_p = 0\n",
    "        \n",
    "        if x.shape[-2] == 1:    # if only one token, then not causal            \n",
    "            is_causal = False\n",
    "        else:\n",
    "            is_causal = True\n",
    "\n",
    "        o = F.scaled_dot_product_attention(q, k, v, dropout_p = dropout_p, is_causal = is_causal)\n",
    "        o = o.permute(0, 2, 1, 3).contiguous().view(o.shape[0], o.shape[2], -1)       # concatenate heads        \n",
    "        o = o @ self.w_o\n",
    "        o = self.dropout(o)\n",
    "\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class Llama2Block(nn.Module):\n",
    "    def __init__(self, config: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.rms = RMSNorm(config.dim)\n",
    "\n",
    "        self.attention = Attention(config)\n",
    "        self.attention_norm = RMSNorm(config.dim, eps = config.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(config.dim, eps = config.norm_eps)\n",
    "        self.ffn_swiglu = FFN_SwiGLU(config)\n",
    "\n",
    "    def forward(self, x, start_pos) -> torch.tensor:\n",
    "        x = x + self.attention(self.attention_norm(x), start_pos)\n",
    "        out = x + self.ffn_swiglu(self.ffn_norm(x))\n",
    "\n",
    "        return out\n",
    "\n",
    "class Llama2(nn.Module):\n",
    "    def __init__(self, config: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        Attention.shared_rope = None    # clear the shared rope defined in Attention class\n",
    "\n",
    "        self.config = config\n",
    "        self.embeddings = nn.Embedding(config.vocab_size, config.dim)\n",
    "        self.llama_blocks = nn.Sequential(\n",
    "            OrderedDict([(f\"LlamaBlock_{i}\", Llama2Block(config)) for i in range(config.n_layers)])\n",
    "        )\n",
    "        self.norm = RMSNorm(config.dim)\n",
    "        self.output = nn.Linear(config.dim, config.vocab_size, bias=False)\n",
    "\n",
    "        print(\"model params:\", sum([m.numel() for m in self.parameters()]))\n",
    "\n",
    "    def forward(self, idx, start_pos = 0, targets = None):\n",
    "        h = self.embeddings(idx)\n",
    "\n",
    "        for block in self.llama_blocks:\n",
    "            h = block(h, start_pos)\n",
    "\n",
    "        h = self.norm(h)\n",
    "        logits = self.output(h)\n",
    "\n",
    "        if targets is None:\n",
    "            return logits\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(-1, self.config.vocab_size), targets.view(-1))\n",
    "            return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "@torch.no_grad()  # don't compute gradients for this function\n",
    "def evaluate_loss(model:Llama2):\n",
    "    config = model.config\n",
    "    out = {}\n",
    "    is_training = model.training\n",
    "\n",
    "    if is_training:\n",
    "        model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = []\n",
    "        for _ in range(10):\n",
    "            xb, yb = get_batches(dataset, split, config.max_batch_size, config.max_seq_len)\n",
    "            _, loss = model(xb, 0, yb)\n",
    "            losses.append(loss.item())\n",
    "        out[split] = np.mean(losses)\n",
    "    if is_training:\n",
    "        model.train()\n",
    "\n",
    "    return out\n",
    "\n",
    "def train(model: Llama2, optimizer:torch.optim.Optimizer, scheduler = None, print_logs = False, log_interval = 100):\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    config = model.config\n",
    "    for epoch in range(config.epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        xs, ys = get_batches(dataset, 'train', config.max_batch_size, config.max_seq_len)\n",
    "        _, loss = model(xs, 0, ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        if epoch % log_interval == 0:\n",
    "            batch_time = time.time() - start_time\n",
    "            x = evaluate_loss(model)\n",
    "            losses += [x]\n",
    "            if print_logs:\n",
    "                print(f\"Epoch {epoch} | val loss {x['val']:.3f} | Time {batch_time:.3f} | ETA in seconds {batch_time * (config.epochs - epoch)/log_interval :.3f}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            if scheduler:\n",
    "                print(\"lr: \", scheduler.get_lr())            \n",
    "\n",
    "    print(\"validation loss: \", losses[-1]['val'])\n",
    "    return pd.DataFrame(losses).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RoPE with shape torch.Size([128, 16])\n",
      "model params: 541824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | val loss 4.189 | Time 0.112 | ETA in seconds 5.596\n",
      "Epoch 100 | val loss 2.315 | Time 9.052 | ETA in seconds 443.572\n",
      "Epoch 200 | val loss 2.093 | Time 7.321 | ETA in seconds 351.408\n",
      "Epoch 300 | val loss 1.929 | Time 7.678 | ETA in seconds 360.888\n",
      "Epoch 400 | val loss 1.861 | Time 8.081 | ETA in seconds 371.710\n",
      "Epoch 500 | val loss 1.831 | Time 8.377 | ETA in seconds 376.968\n",
      "Epoch 600 | val loss 1.761 | Time 8.864 | ETA in seconds 390.000\n",
      "Epoch 700 | val loss 1.761 | Time 8.860 | ETA in seconds 380.991\n",
      "Epoch 800 | val loss 1.731 | Time 8.809 | ETA in seconds 369.998\n",
      "Epoch 900 | val loss 1.684 | Time 8.907 | ETA in seconds 365.184\n",
      "Epoch 1000 | val loss 1.683 | Time 8.804 | ETA in seconds 352.153\n",
      "Epoch 1100 | val loss 1.688 | Time 8.671 | ETA in seconds 338.164\n",
      "Epoch 1200 | val loss 1.669 | Time 8.735 | ETA in seconds 331.942\n",
      "Epoch 1300 | val loss 1.684 | Time 8.759 | ETA in seconds 324.081\n",
      "Epoch 1400 | val loss 1.631 | Time -561.156 | ETA in seconds -20201.631\n",
      "Epoch 1500 | val loss 1.643 | Time 8.785 | ETA in seconds 307.460\n",
      "Epoch 1600 | val loss 1.633 | Time 9.321 | ETA in seconds 316.900\n",
      "Epoch 1700 | val loss 1.616 | Time 579.614 | ETA in seconds 19127.272\n",
      "Epoch 1800 | val loss 1.598 | Time 9.592 | ETA in seconds 306.929\n",
      "Epoch 1900 | val loss 1.620 | Time 9.034 | ETA in seconds 280.045\n",
      "Epoch 2000 | val loss 1.598 | Time 8.936 | ETA in seconds 268.080\n",
      "Epoch 2100 | val loss 1.617 | Time 8.732 | ETA in seconds 253.229\n",
      "Epoch 2200 | val loss 1.568 | Time 8.789 | ETA in seconds 246.098\n",
      "Epoch 2300 | val loss 1.599 | Time 9.032 | ETA in seconds 243.852\n",
      "Epoch 2400 | val loss 1.569 | Time 9.199 | ETA in seconds 239.169\n",
      "Epoch 2500 | val loss 1.539 | Time 8.941 | ETA in seconds 223.518\n",
      "Epoch 2600 | val loss 1.557 | Time 8.771 | ETA in seconds 210.514\n",
      "Epoch 2700 | val loss 1.588 | Time 8.696 | ETA in seconds 200.007\n",
      "Epoch 2800 | val loss 1.581 | Time 8.762 | ETA in seconds 192.761\n",
      "Epoch 2900 | val loss 1.564 | Time 8.686 | ETA in seconds 182.403\n",
      "Epoch 3000 | val loss 1.561 | Time 8.734 | ETA in seconds 174.673\n",
      "Epoch 3100 | val loss 1.569 | Time 8.934 | ETA in seconds 169.743\n",
      "Epoch 3200 | val loss 1.542 | Time 8.961 | ETA in seconds 161.292\n",
      "Epoch 3300 | val loss 1.577 | Time 8.900 | ETA in seconds 151.304\n",
      "Epoch 3400 | val loss 1.565 | Time 8.992 | ETA in seconds 143.879\n",
      "Epoch 3500 | val loss 1.540 | Time 8.791 | ETA in seconds 131.871\n",
      "Epoch 3600 | val loss 1.526 | Time 9.088 | ETA in seconds 127.239\n",
      "Epoch 3700 | val loss 1.529 | Time 9.175 | ETA in seconds 119.279\n",
      "Epoch 3800 | val loss 1.535 | Time 9.000 | ETA in seconds 108.001\n",
      "Epoch 3900 | val loss 1.571 | Time 8.917 | ETA in seconds 98.090\n",
      "Epoch 4000 | val loss 1.521 | Time 8.721 | ETA in seconds 87.209\n",
      "Epoch 4100 | val loss 1.546 | Time 8.648 | ETA in seconds 77.834\n",
      "Epoch 4200 | val loss 1.551 | Time 8.821 | ETA in seconds 70.566\n",
      "Epoch 4300 | val loss 1.543 | Time 8.934 | ETA in seconds 62.541\n",
      "Epoch 4400 | val loss 1.517 | Time 8.636 | ETA in seconds 51.814\n",
      "Epoch 4500 | val loss 1.532 | Time 8.714 | ETA in seconds 43.571\n",
      "Epoch 4600 | val loss 1.537 | Time 8.615 | ETA in seconds 34.459\n",
      "Epoch 4700 | val loss 1.512 | Time 8.863 | ETA in seconds 26.590\n",
      "Epoch 4800 | val loss 1.514 | Time 8.715 | ETA in seconds 17.430\n",
      "Epoch 4900 | val loss 1.543 | Time 8.604 | ETA in seconds 8.604\n",
      "validation loss:  1.5431029438972472\n",
      "CPU times: user 1h 17min 10s, sys: 32.2 s, total: 1h 17min 42s\n",
      "Wall time: 7min 46s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "llama = Llama2(model_config)\n",
    "optimizer = torch.optim.Adam(llama.parameters())\n",
    "train(llama, optimizer, print_logs=True)\n",
    "\n",
    "# Save\n",
    "now = datetime.now()\n",
    "model_name = f'./checkpoint/llama2_L{model_config.n_layers}xH{model_config.n_heads}xN{model_config.max_seq_len}xD{model_config.dim}_{now.year}_{now.month}_{now.day}_{now.hour}_{now.minute}.pth'\n",
    "torch.save({'model_state_dict': llama.state_dict()}, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model : Llama2, max_new_tokens = 10):\n",
    "    model.eval()\n",
    "    config = model.config\n",
    "    max_new_tokens = model.config.max_seq_len if max_new_tokens > model.config.max_seq_len else max_new_tokens\n",
    "    idx = torch.zeros(config.max_batch_size, 1).long()\n",
    "\n",
    "    start_pos = 0\n",
    "    for i in range(max_new_tokens):\n",
    "        if i == 0:\n",
    "            logits = model(idx)\n",
    "        else:\n",
    "            logits = model(idx[:, -1].unsqueeze(-1), start_pos)\n",
    "            # logits = model(idx[:, -config.max_seq_len:], 0)\n",
    "        \n",
    "        last_time_step_logits = logits[:, -1, :]            # all the batches (1), last time step, all the logits\n",
    "        p = F.softmax(last_time_step_logits, dim=-1)        # softmax to get probabilities\n",
    "        idx_next = torch.multinomial(\n",
    "            p, num_samples=1\n",
    "        )                                                   # sample from the distribution to get the next token\n",
    "\n",
    "        start_pos = idx.shape[-1]\n",
    "        idx = torch.cat([idx, idx_next], dim=-1)            # append to the sequence\n",
    "                    \n",
    "    return [decode(x) for x in idx.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RoPE with shape torch.Size([128, 16])\n",
      "model params: 541824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "## Get lastest checkpoint\n",
    "files = glob.glob('./checkpoint/*.pth')\n",
    "files.sort(key=os.path.getmtime)\n",
    "model_name = files[-1]\n",
    "\n",
    "llama_infer = Llama2(model_config)\n",
    "llama_infer.load_state_dict(torch.load(model_name)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On the for me wont them let that give me oaths.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "I Montague?\n",
      "\n",
      "HASTINGS:\n",
      "Now, let than\n",
      "\n",
      "LUCIO:\n",
      "Nay, for that your lords flightly world:\n",
      "I know thoughts thou we exposed her for his\n",
      "and fait\n",
      "\n",
      "My that ever braids thou filed. To hearts my hings,\n",
      "Or Fourthless that to us to makes off servingman\n",
      "\n",
      "QUEEN ELIZABETH: thou talk him safety sorrow.\n",
      "Jay, that is do couragest, no that as unchase thou sho\n",
      "\n",
      "And would as not be upon villain, but Edward's royal have of an osle\n",
      "In they feed me fear'd honestly\n",
      "\n",
      "3 LIAFFORD:\n",
      "Your'd have heard From we'll hanither hands,\n",
      "And what this personant with to sight subtl\n",
      "\n",
      "\n",
      "'Tis woring is mother is osly.\n",
      "\n",
      "BRUTUS:\n",
      "Tus good gone this last, and fleshment's away.\n",
      "\n",
      "QUEEN MARGA\n",
      "\n",
      "As thou nothing for the Meenger: but sir.\n",
      "\n",
      "MessengerLeGk, the Duke of Gaunt it her ears, if this bro\n",
      "\n",
      "\n",
      "And gentlemen, sweeks.\n",
      "\n",
      "ANGELO:\n",
      "Go me so; I best the tape\n",
      "Pity! O shameleo prison of to there,\n",
      "I ne\n",
      "\n",
      "As mine away a Tybalt\n",
      "Come, that know a gentlemen. The man? O! we have strengthen your all eyes,\n",
      "Or \n",
      "\n",
      "Shall burial the strike your night, thy guidenger grace.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "And that whom sounded of t\n",
      "\n",
      "\n",
      "\n",
      "your counto my interr part it inshellow.\n",
      "Hadst thou of the sarly bless God's child--that friends:\n",
      "\n",
      "\n",
      "No here in but not help the king again.\n",
      "\n",
      "MENENIUS:\n",
      "Aumerle, my glory have forth?\n",
      "\n",
      "Mayor, from the ri\n",
      "\n",
      "KING HENRY VI:\n",
      "Go, lords, I peever Edward's lords stige of a murder-upon yours.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "An\n",
      "\n",
      "Citizens, being should queen of the meet o'er-son?\n",
      "Recurent the keep in my remedict;\n",
      "For I do them t\n",
      "\n",
      "STANLEY:\n",
      "Nimple of make sweet hope, from Great\n",
      "Fucitters him for'd tup how.\n",
      "\n",
      "CLARENCE:\n",
      "I now there o\n",
      "\n",
      "ISABELLA:\n",
      "Even refuser Mething own such less amen bold\n",
      "Unreat this as fitle. Mistress me death;\n",
      "When\n",
      "\n",
      "The king die in extop of the gentleman to except.\n",
      "\n",
      "First Cuprovost, thou wounded of be they have mou\n",
      "\n",
      "Phampege, you expedinal of Rain this joy.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Pray whom where she  is yourself to powe\n",
      "\n",
      "\n",
      "ANGELO:\n",
      "Go, you the time and he was piece my rever'd;\n",
      "And for my adventure young the orne's hath\n",
      "Ye\n",
      "\n",
      "All the work ratches hath horrow, to signty!\n",
      "Thou do I have county that us, if our all us;\n",
      "And spiri\n",
      "\n",
      "LEONTES:\n",
      "Lourself to Large Margaret calls an an that\n",
      "And rid in this guilty\n",
      "In rather, fine shows bl\n",
      "\n",
      "\n",
      "MONTAGUE:\n",
      "What had I bawd with her, 'tis best most of that dain?\n",
      "\n",
      "The this the vast for person's Ch\n",
      "\n",
      "KING EDWARD IV:\n",
      "Advance take it bold, will follow.\n",
      "\n",
      "KING HENRY VI:\n",
      "A gold with a man, I'ld of you. O\n",
      "\n",
      "Had his gone proof good puts her one!\n",
      "Long Tarqual I bite within win the ignoble and make.\n",
      "\n",
      "QUEEN:\n",
      "B\n",
      "\n",
      "That I do soon! 'She but vy do my master.\n",
      "\n",
      "GLOUCESTER:\n",
      "A mine is shall have no fage a county'd hand'\n",
      "\n",
      "Can directedion with the overy threegner;\n",
      "Desperate stands for your souls more spity.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Y\n",
      "\n",
      "I men shame a discover body proved attempt of past,\n",
      "Or Ireland's thine ever the us to Have them.\n",
      "Wha\n",
      "\n",
      "This rise your help sweet ime are unplease for the reders;\n",
      "Or swift this unker of this wise out fair\n",
      "\n",
      "Servant:\n",
      "I may news he writ den in false? Even now sake.\n",
      "\n",
      "PAULINA:\n",
      "Arfles boswear thou like this of \n",
      "\n",
      "\n",
      "\n",
      "QUEEN:\n",
      "To mean that every true made it away! wrels!\n",
      "Heaven, the censed likely peaced your bold, ho\n",
      "\n",
      "That; but want rise on dispatch chair.\n",
      "\n",
      "BUCKINGHAM:\n",
      "How! mistakest not mother thing Did such,\n",
      "Or buc\n",
      "CPU times: user 1.88 s, sys: 20 ms, total: 1.9 s\n",
      "Wall time: 191 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for s in generate(llama_infer, 100):\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-fundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
