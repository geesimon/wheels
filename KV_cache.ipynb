{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelArgs(dim=128, n_layers=4, n_heads=8, n_kv_heads=None, vocab_size=-1, multiple_of=256, ffn_dim_multiplier=None, norm_eps=1e-05, max_batch_size=32, max_seq_len=16, epochs=10000)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 128\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 8\n",
    "    n_kv_heads: Optional[int] = None\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    ffn_dim_multiplier: Optional[float] = None\n",
    "    norm_eps: float = 1e-5\n",
    "\n",
    "    max_batch_size: int = 32\n",
    "    max_seq_len: int = 16\n",
    "\n",
    "    epochs: int = 10_000    \n",
    "\n",
    "model_config = ModelArgs()\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 1115394\n"
     ]
    }
   ],
   "source": [
    "# simple tokenization by characters\n",
    "def encode(s):\n",
    "    return [stoi[ch] for ch in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "\n",
    "lines = open('./data/Shakespeare.txt', 'r').read()\n",
    "vocab = sorted(list(set(lines)))\n",
    "itos = {i:ch for i, ch in enumerate(vocab)}\n",
    "stoi = {ch:i for i, ch in enumerate(vocab)}\n",
    "dataset = torch.tensor(encode(lines), dtype=torch.int8)\n",
    "print(f'Sentences: {dataset.shape[0]}')\n",
    "\n",
    "model_config.vocab_size = len(vocab)\n",
    "\n",
    "def get_batches(data, split, batch_size, context_window):\n",
    "    train = data[:int(.8 * len(data))]\n",
    "    val = data[int(.8 * len(data)): int(.9 * len(data))]\n",
    "    test = data[int(.9 * len(data)):]\n",
    "\n",
    "    if split == 'train':\n",
    "        batch_data = train\n",
    "    elif split == 'test':\n",
    "        batch_data = test\n",
    "    else:\n",
    "        batch_data = val\n",
    "\n",
    "    # pick random starting points\n",
    "    ix = torch.randint(0, batch_data.size(0) - context_window - 1, (batch_size,))\n",
    "    x = torch.stack([batch_data[i:i+context_window] for i in ix]).long()\n",
    "    y = torch.stack([batch_data[i+1:i+context_window+1] for i in ix]).long()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS Normalization \n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/1910.07467.pdf)\n",
    "- [Reference implementation](https://github.com/facebookresearch/llama/blob/54d44631054deae836aec8ceff92dcf8f20ca9e7/llama/model.py#L34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Initialize the RMSNorm normalization layer.\n",
    "\n",
    "        Args:\n",
    "            dim (int): The dimension of the input tensor.\n",
    "            eps (float, optional): A small value added to the denominator for numerical stability. Default is 1e-6.\n",
    "\n",
    "        Attributes:\n",
    "            eps (float): A small value added to the denominator for numerical stability.\n",
    "            weight (nn.Parameter): Learnable scaling parameter.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x : torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Apply the RMSNorm normalization to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The normalized tensor.\n",
    "\n",
    "        \"\"\"\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the RMSNorm layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor after applying RMSNorm.\n",
    "\n",
    "        \"\"\"        \n",
    "        return self._norm(x.float()).type_as(x) * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoPE\n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/2104.09864.pdf)\n",
    "- [Reference Implementation](https://github.com/facebookresearch/llama/blob/dccf644213a2771a81fc4a754eed9623ea7f8444/llama/model.py#L80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPE:\n",
    "    def __init__(self, dim: int, max_seq_len: int, theta: float = 10000.0):\n",
    "        \"\"\"\n",
    "        Precompute the frequency tensor for complex exponentials (cis, defined as 'm*theta_i' in the paper) \n",
    "        with given dimensions.\n",
    "\n",
    "        Calculates a frequency tensor with complex exponentials using the given dimension 'dim'\n",
    "        and the max sequence length. The 'theta_base' parameter scales the frequencies.\n",
    "        The returned tensor contains complex values in complex64 data type.\n",
    "\n",
    "        Args:\n",
    "            dim (int): Dimension of the frequency tensor.\n",
    "            max_seq_len (int): Max sequence length.\n",
    "            theta_base (float, optional): Scaling factor for frequency computation. Defaults to 10000.0.\n",
    "        \"\"\"\n",
    "        freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "        freqs = torch.outer(torch.arange(max_seq_len), freqs).float()\n",
    "        self.freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "        print(f\"Rope Initialized! dim:{dim} max_seq_len:{max_seq_len}\")\n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply rotary embeddings to input tensors using the given frequency tensor.\n",
    "\n",
    "        This function first reshapes the frequency tensor to have the same shape as the target tensor 'x'\n",
    "        for the purpose of broadcasting the frequency tensor during element-wise operations. Then, it applies \n",
    "        rotary embeddings to 'x' tensor using frequency tensor 'freqs_cis'.         \n",
    "        \"\"\"\n",
    "        x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2))\n",
    "\n",
    "        shape = [d if i == 1 or i == x.ndim - 1 else 1 for i, d in enumerate(x_complex.shape)]\n",
    "        freqs_cis = self.freqs_cis[:x.shape[-2]].view(*shape)  \n",
    "                \n",
    "        x_real = torch.view_as_real(x_complex * freqs_cis).flatten(-2)\n",
    "        \n",
    "        return x_real.type_as(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoPE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rope Initialized! dim:128 max_seq_len:256\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "dim = 128\n",
    "max_seq_len = 256\n",
    "\n",
    "def get_rotary_matrix(context_window, embedding_dim):\n",
    "    R = torch.zeros((context_window, embedding_dim, embedding_dim), requires_grad=False)\n",
    "    for position in range(context_window):\n",
    "        for i in range(embedding_dim//2):\n",
    "            theta = 10000. ** (-2.*i / embedding_dim)\n",
    "            m_theta = position * theta\n",
    "            R[position, 2*i,2*i] = np.cos(m_theta)\n",
    "            R[position, 2*i,2*i+1] = - np.sin(m_theta)\n",
    "            R[position, 2*i+1,2*i] = np.sin(m_theta)\n",
    "            R[position, 2*i+1,2*i+1] = np.cos(m_theta)\n",
    "    return R\n",
    "\n",
    "R = get_rotary_matrix(max_seq_len, dim)\n",
    "\n",
    "X= torch.ones(1, max_seq_len, dim)\n",
    "rope = RoPE(dim=dim, max_seq_len=max_seq_len)\n",
    "X1 = rope(X)\n",
    "X2 = (R @ X.unsqueeze(-1)).flatten(-2)\n",
    "\n",
    "print(X1.allclose(X2, atol=1e-3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    shared_rope : RoPE = None\n",
    "\n",
    "    def __init__(self, config : ModelArgs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        if Attention.shared_rope is None:\n",
    "            Attention.shared_rope = RoPE(config.dim, config.max_seq_len)\n",
    "\n",
    "        self.w_q = nn.Linear(config.dim, config.dim, bias=False)\n",
    "        self.w_k = nn.Linear(config.dim, config.dim, bias=False)\n",
    "        self.w_v = nn.Linear(config.dim, config.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        q = self.w_q(x)\n",
    "        k = self.w_k(x)\n",
    "        v = self.w_v(x)\n",
    "\n",
    "        # if not self.training:\n",
    "        #     print('inference')\n",
    "        # if 'inference' in self.config and self.config['inference']:  # implement KV cache\n",
    "        #     if x.shape[-2] > 1:  #reset kv cache for new sentence\n",
    "        #         self.k = k\n",
    "        #         self.v = v\n",
    "        #     else:\n",
    "        #         self.k = torch.concat([self.k[:, -self.config.max_seq_len + 1:], k], dim = -2)\n",
    "        #         self.v = torch.concat([self.v[:, -self.config.max_seq_len + 1:], v], dim = -2)            \n",
    "        #         k, v = self.k, self.v\n",
    "        \n",
    "        q_rotated = Attention.shared_rope(q)\n",
    "        k_rotated = Attention.shared_rope(k)\n",
    "\n",
    "        activations = F.scaled_dot_product_attention(\n",
    "            q_rotated, k_rotated, v, dropout_p =.1, is_causal=True\n",
    "        )\n",
    "\n",
    "        return activations\n",
    "\n",
    "\n",
    "class MaskedMultiheadAttention(nn.Module):\n",
    "    def __init__(self, config: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.heads = nn.ModuleList([\n",
    "            Attention(config) for _ in range(config.n_heads)\n",
    "        ])\n",
    "        self.linear = nn.Linear(config.n_heads * config.dim, config.dim)\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "\n",
    "    def forward(self, x : torch.tensor) -> torch.tensor:\n",
    "        heads = [h(x) for h in self.heads]\n",
    "        x = torch.cat(heads, dim=-1)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.linear_gate = nn.Linear(size, size)\n",
    "        self.linear = nn.Linear(size, size)\n",
    "\n",
    "        self.beta = torch.ones(1, requires_grad=True)\n",
    "\n",
    "    def forward(self, x): \n",
    "        swish_gate = self.linear_gate(x) * torch.sigmoid(self.beta * self.linear_gate(x))\n",
    "        out = swish_gate * self.linear(x)\n",
    "        return out\n",
    "\n",
    "class LlamaBlock(nn.Module):\n",
    "    def __init__(self, config: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.rms = RMSNorm(config.dim)\n",
    "\n",
    "        self.attention = MaskedMultiheadAttention(config)\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(config.dim, config.dim),\n",
    "            SwiGLU(config.dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> torch.tensor:\n",
    "        x = self.rms(x) # rms pre-normalization\n",
    "        x = x + self.attention(x)\n",
    "\n",
    "        x = self.rms(x) # rms pre-normalization\n",
    "        x = x + self.feedforward(x)\n",
    "        return x\n",
    "\n",
    "class Llama(nn.Module):\n",
    "    def __init__(self, config: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embeddings = nn.Embedding(config.vocab_size, config.dim)\n",
    "        self.llama_blocks = nn.Sequential(\n",
    "            OrderedDict([(f\"llama_{i}\", LlamaBlock(config)) for i in range(config.n_layers)])\n",
    "        )\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(config.dim, config.dim),\n",
    "            SwiGLU(config.dim),\n",
    "            nn.Linear(config.dim, config.vocab_size),\n",
    "        )\n",
    "\n",
    "        print(\"model params:\", sum([m.numel() for m in self.parameters()]))\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        x = self.embeddings(idx)\n",
    "        x = self.llama_blocks(x)\n",
    "        logits = self.ffn(x)\n",
    "\n",
    "        if targets is None:\n",
    "            return logits\n",
    "\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(-1, self.config.vocab_size), targets.view(-1))\n",
    "            return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()  # don't compute gradients for this function\n",
    "def evaluate_loss(model:nn.modules, config:ModelArgs):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = []\n",
    "        for _ in range(10):\n",
    "            xb, yb = get_batches(dataset, split, config.vocab_size, config.max_seq_len)\n",
    "            _, loss = model(xb, yb)\n",
    "            losses.append(loss.item())\n",
    "        out[split] = np.mean(losses)\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "def train(model: Llama, optimizer:torch.optim.Optimizer, scheduler = None, print_logs = False, log_interval = 100):\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    config = model.config\n",
    "    for epoch in range(config.epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        xs, ys = get_batches(dataset, 'train', config.max_batch_size, config.max_seq_len)\n",
    "        _, loss = model(xs, targets=ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if epoch % log_interval == 0:\n",
    "            batch_time = time.time() - start_time\n",
    "            x = evaluate_loss(model, config)\n",
    "            losses += [x]\n",
    "            if print_logs:\n",
    "                print(f\"Epoch {epoch} | val loss {x['val']:.3f} | Time {batch_time:.3f} | ETA in seconds {batch_time * (config.epochs - epoch)/log_interval :.3f}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            if scheduler:\n",
    "                print(\"lr: \", scheduler.get_lr())\n",
    "\n",
    "    # print(pd.DataFrame(losses))\n",
    "    print(\"validation loss: \", losses[-1]['val'])\n",
    "    return pd.DataFrame(losses).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rope Initialized! dim:128 max_seq_len:16\n",
      "model params: 2362561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | val loss 4.125 | Time 0.176 | ETA in seconds 17.615\n",
      "Epoch 100 | val loss 2.422 | Time 9.828 | ETA in seconds 972.948\n",
      "Epoch 200 | val loss 2.236 | Time 7.965 | ETA in seconds 780.567\n",
      "Epoch 300 | val loss 2.161 | Time 7.724 | ETA in seconds 749.254\n",
      "Epoch 400 | val loss 2.124 | Time 8.442 | ETA in seconds 810.449\n",
      "Epoch 500 | val loss 2.094 | Time 9.487 | ETA in seconds 901.221\n",
      "Epoch 600 | val loss 2.083 | Time 11.217 | ETA in seconds 1054.361\n",
      "Epoch 700 | val loss 2.021 | Time 8.895 | ETA in seconds 827.235\n",
      "Epoch 800 | val loss 2.033 | Time 10.742 | ETA in seconds 988.266\n",
      "Epoch 900 | val loss 1.992 | Time 15.956 | ETA in seconds 1452.038\n",
      "Epoch 1000 | val loss 1.978 | Time 28.623 | ETA in seconds 2576.106\n",
      "Epoch 1100 | val loss 1.965 | Time 22.710 | ETA in seconds 2021.161\n",
      "Epoch 1200 | val loss 1.998 | Time 26.694 | ETA in seconds 2349.055\n",
      "Epoch 1300 | val loss 1.984 | Time 29.306 | ETA in seconds 2549.593\n",
      "Epoch 1400 | val loss 1.939 | Time 16.862 | ETA in seconds 1450.100\n",
      "Epoch 1500 | val loss 1.937 | Time 16.830 | ETA in seconds 1430.577\n",
      "Epoch 1600 | val loss 1.969 | Time 16.972 | ETA in seconds 1425.616\n",
      "Epoch 1700 | val loss 1.917 | Time 17.970 | ETA in seconds 1491.551\n",
      "Epoch 1800 | val loss 1.946 | Time 17.155 | ETA in seconds 1406.717\n",
      "Epoch 1900 | val loss 1.921 | Time 16.772 | ETA in seconds 1358.515\n",
      "Epoch 2000 | val loss 1.901 | Time 16.645 | ETA in seconds 1331.565\n",
      "Epoch 2100 | val loss 1.911 | Time 17.224 | ETA in seconds 1360.702\n",
      "Epoch 2200 | val loss 1.893 | Time 16.714 | ETA in seconds 1303.664\n",
      "Epoch 2300 | val loss 1.930 | Time 16.213 | ETA in seconds 1248.389\n",
      "Epoch 2400 | val loss 1.885 | Time 16.704 | ETA in seconds 1269.497\n",
      "Epoch 2500 | val loss 1.873 | Time 16.235 | ETA in seconds 1217.634\n",
      "Epoch 2600 | val loss 1.889 | Time 16.200 | ETA in seconds 1198.818\n",
      "Epoch 2700 | val loss 1.868 | Time 16.254 | ETA in seconds 1186.554\n",
      "Epoch 2800 | val loss 1.840 | Time 16.522 | ETA in seconds 1189.553\n",
      "Epoch 2900 | val loss 1.872 | Time 16.025 | ETA in seconds 1137.758\n",
      "Epoch 3000 | val loss 1.855 | Time 16.927 | ETA in seconds 1184.903\n",
      "Epoch 3100 | val loss 1.825 | Time 18.459 | ETA in seconds 1273.680\n",
      "Epoch 3200 | val loss 1.853 | Time 19.871 | ETA in seconds 1351.249\n",
      "Epoch 3300 | val loss 1.842 | Time 20.520 | ETA in seconds 1374.824\n",
      "Epoch 3400 | val loss 1.862 | Time 20.036 | ETA in seconds 1322.372\n",
      "Epoch 3500 | val loss 1.850 | Time 23.109 | ETA in seconds 1502.106\n",
      "Epoch 3600 | val loss 1.846 | Time 21.589 | ETA in seconds 1381.703\n",
      "Epoch 3700 | val loss 1.882 | Time 22.143 | ETA in seconds 1395.011\n",
      "Epoch 3800 | val loss 1.854 | Time 21.879 | ETA in seconds 1356.473\n",
      "Epoch 3900 | val loss 1.845 | Time 22.427 | ETA in seconds 1368.035\n",
      "Epoch 4000 | val loss 1.849 | Time 21.838 | ETA in seconds 1310.303\n",
      "Epoch 4100 | val loss 1.843 | Time 21.780 | ETA in seconds 1285.015\n",
      "Epoch 4200 | val loss 1.834 | Time 22.567 | ETA in seconds 1308.877\n",
      "Epoch 4300 | val loss 1.783 | Time 19.723 | ETA in seconds 1124.212\n",
      "Epoch 4400 | val loss 1.827 | Time 19.695 | ETA in seconds 1102.906\n",
      "Epoch 4500 | val loss 1.846 | Time 19.414 | ETA in seconds 1067.768\n",
      "Epoch 4600 | val loss 1.825 | Time 19.717 | ETA in seconds 1064.729\n",
      "Epoch 4700 | val loss 1.823 | Time 19.782 | ETA in seconds 1048.454\n",
      "Epoch 4800 | val loss 1.799 | Time 19.698 | ETA in seconds 1024.293\n",
      "Epoch 4900 | val loss 1.806 | Time 19.933 | ETA in seconds 1016.592\n",
      "Epoch 5000 | val loss 1.847 | Time 19.594 | ETA in seconds 979.703\n",
      "Epoch 5100 | val loss 1.864 | Time 20.059 | ETA in seconds 982.906\n",
      "Epoch 5200 | val loss 1.805 | Time 19.712 | ETA in seconds 946.161\n",
      "Epoch 5300 | val loss 1.836 | Time 20.930 | ETA in seconds 983.694\n",
      "Epoch 5400 | val loss 1.863 | Time 19.951 | ETA in seconds 917.743\n",
      "Epoch 5500 | val loss 1.792 | Time 20.910 | ETA in seconds 940.954\n",
      "Epoch 5600 | val loss 1.817 | Time 18.759 | ETA in seconds 825.398\n",
      "Epoch 5700 | val loss 1.788 | Time 18.712 | ETA in seconds 804.607\n",
      "Epoch 5800 | val loss 1.822 | Time 25.777 | ETA in seconds 1082.615\n",
      "Epoch 5900 | val loss 1.820 | Time 22.358 | ETA in seconds 916.662\n",
      "Epoch 6000 | val loss 1.821 | Time 18.521 | ETA in seconds 740.820\n",
      "Epoch 6100 | val loss 1.826 | Time 17.655 | ETA in seconds 688.539\n",
      "Epoch 6200 | val loss 1.824 | Time 17.474 | ETA in seconds 664.010\n",
      "Epoch 6300 | val loss 1.848 | Time 17.048 | ETA in seconds 630.782\n",
      "Epoch 6400 | val loss 1.775 | Time 17.277 | ETA in seconds 621.976\n",
      "Epoch 6500 | val loss 1.801 | Time 17.251 | ETA in seconds 603.801\n",
      "Epoch 6600 | val loss 1.810 | Time 17.889 | ETA in seconds 608.209\n",
      "Epoch 6700 | val loss 1.870 | Time 16.773 | ETA in seconds 553.496\n",
      "Epoch 6800 | val loss 1.813 | Time 17.983 | ETA in seconds 575.471\n",
      "Epoch 6900 | val loss 1.784 | Time 17.734 | ETA in seconds 549.744\n",
      "Epoch 7000 | val loss 1.795 | Time 18.055 | ETA in seconds 541.644\n",
      "Epoch 7100 | val loss 1.760 | Time 17.916 | ETA in seconds 519.568\n",
      "Epoch 7200 | val loss 1.790 | Time 21.517 | ETA in seconds 602.466\n",
      "Epoch 7300 | val loss 1.824 | Time 23.017 | ETA in seconds 621.464\n",
      "Epoch 7400 | val loss 1.777 | Time 18.299 | ETA in seconds 475.779\n",
      "Epoch 7500 | val loss 1.787 | Time 18.032 | ETA in seconds 450.799\n",
      "Epoch 7600 | val loss 1.771 | Time 20.457 | ETA in seconds 490.972\n",
      "Epoch 7700 | val loss 1.769 | Time 21.818 | ETA in seconds 501.815\n",
      "Epoch 7800 | val loss 1.810 | Time 17.815 | ETA in seconds 391.939\n",
      "Epoch 7900 | val loss 1.819 | Time 25.102 | ETA in seconds 527.138\n",
      "Epoch 8000 | val loss 1.791 | Time 17.232 | ETA in seconds 344.649\n",
      "Epoch 8100 | val loss 1.792 | Time 17.188 | ETA in seconds 326.569\n",
      "Epoch 8200 | val loss 1.788 | Time 16.695 | ETA in seconds 300.506\n",
      "Epoch 8300 | val loss 1.807 | Time 17.588 | ETA in seconds 299.003\n",
      "Epoch 8400 | val loss 1.801 | Time 16.826 | ETA in seconds 269.215\n",
      "Epoch 8500 | val loss 1.780 | Time 16.885 | ETA in seconds 253.281\n",
      "Epoch 8600 | val loss 1.768 | Time 16.601 | ETA in seconds 232.407\n",
      "Epoch 8700 | val loss 1.802 | Time 16.370 | ETA in seconds 212.810\n",
      "Epoch 8800 | val loss 1.785 | Time 17.410 | ETA in seconds 208.919\n",
      "Epoch 8900 | val loss 1.784 | Time 17.095 | ETA in seconds 188.041\n",
      "Epoch 9000 | val loss 1.806 | Time 17.000 | ETA in seconds 170.002\n",
      "Epoch 9100 | val loss 1.766 | Time 16.581 | ETA in seconds 149.231\n",
      "Epoch 9200 | val loss 1.772 | Time 16.665 | ETA in seconds 133.322\n",
      "Epoch 9300 | val loss 1.776 | Time 17.186 | ETA in seconds 120.304\n",
      "Epoch 9400 | val loss 1.759 | Time 17.414 | ETA in seconds 104.483\n",
      "Epoch 9500 | val loss 1.748 | Time 19.214 | ETA in seconds 96.071\n",
      "Epoch 9600 | val loss 1.805 | Time 17.974 | ETA in seconds 71.898\n",
      "Epoch 9700 | val loss 1.780 | Time 18.069 | ETA in seconds 54.206\n",
      "Epoch 9800 | val loss 1.779 | Time 17.973 | ETA in seconds 35.946\n",
      "Epoch 9900 | val loss 1.812 | Time 18.097 | ETA in seconds 18.097\n",
      "validation loss:  1.811555802822113\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'now' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:8\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'now' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "llama = Llama(model_config)\n",
    "optimizer = torch.optim.Adam(llama.parameters())\n",
    "train(llama, optimizer, print_logs=True)\n",
    "\n",
    "# Save\n",
    "now = datetime.now()\n",
    "model_name = f'./checkpoint/llama_{now.year}_{now.month}_{now.day}_{now.hour}_{now.minute}.pth'\n",
    "torch.save({'model_state_dict': llama.state_dict()}, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model : Llama, max_new_tokens=30):\n",
    "    model.eval()\n",
    "    config = model.config\n",
    "    idx = torch.zeros(config.max_batch_size, 2).long()\n",
    "\n",
    "    for i in range(max_new_tokens):\n",
    "        if i == 0:\n",
    "            logits = model(idx)\n",
    "        else:\n",
    "            # logits = model(idx[:, -1].unsqueeze(1))\n",
    "            logits = model(idx[:, -config.max_seq_len:])\n",
    "        # print(f'logits:{logits[:, -1, :5]}')\n",
    "            \n",
    "        last_time_step_logits = logits[:, -1, :]            # all the batches (1), last time step, all the logits\n",
    "        p = F.softmax(last_time_step_logits, dim=-1)        # softmax to get probabilities\n",
    "        idx_next = torch.multinomial(\n",
    "            p, num_samples=1\n",
    "        )                                                   # sample from the distribution to get the next token\n",
    "        idx = torch.cat([idx, idx_next], dim=-1)            # append to the sequence\n",
    "    \n",
    "    return [decode(x) for x in idx.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 2362561\n",
      "\n",
      "\n",
      "OSTER:\n",
      "My lord, or east him you their with a giffe by the brother.\n",
      "\n",
      "Metle feen contageful to a both.\n",
      "CPU times: user 9.11 s, sys: 9.99 ms, total: 9.12 s\n",
      "Wall time: 945 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_config.max_batch_size = 1\n",
    "\n",
    "llama_infer = Llama(model_config)\n",
    "llama_infer.load_state_dict(torch.load(model_name)['model_state_dict'])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "print(generate(llama_infer, 100)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-fundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
