{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absmax_quantize_i8(X: torch.Tensor):\n",
    "    absmax = torch.max(torch.abs(X))\n",
    "    X_i8 = ((X * 127) / absmax).to(torch.int8)\n",
    "    return X_i8, X_i8.to(torch.float32) * absmax / 127\n",
    "\n",
    "def zeropoint_quantize_i8(X: torch.Tensor):\n",
    "    r = torch.max(X) - torch.min(X)\n",
    "    r = 1 if r == 0 else r\n",
    "    scale = 255 / r\n",
    "\n",
    "    zeropoint = (-scale * torch.min(X) - 128)\n",
    "    X_i8 =  (X * scale + zeropoint).round().to(torch.int8)\n",
    "    \n",
    "    return X_i8, (X_i8 - zeropoint) / scale\n",
    "\n",
    "def zeropoint_quantize(X):\n",
    "    # Calculate value range (denominator)\n",
    "    x_range = torch.max(X) - torch.min(X)\n",
    "    x_range = 1 if x_range == 0 else x_range\n",
    "\n",
    "    # Calculate scale\n",
    "    scale = 255 / x_range\n",
    "\n",
    "    # Shift by zero-point\n",
    "    zeropoint = (-scale * torch.min(X) - 128).round()\n",
    "    # Scale and round the inputs\n",
    "    X_quant = torch.clip((X * scale + zeropoint).round(), -128, 127)\n",
    "\n",
    "    # Dequantize\n",
    "    X_dequant = (X_quant - zeropoint) / scale\n",
    "\n",
    "    return X_quant.to(torch.int8), X_dequant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_vector_abs_i8(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n",
    "    A_scale = 127 / torch.max(torch.abs(A), dim=1).values\n",
    "    B_scale = 127 / torch.max(torch.abs(B), dim=0).values\n",
    "    C_scale = torch.matmul(A_scale.unsqueeze(1), B_scale.unsqueeze(0))\n",
    "\n",
    "    A_i8 = (A  * A_scale.unsqueeze(1)).round().to(torch.int8)\n",
    "    B_i8 = (B  * B_scale.unsqueeze(0)).round().to(torch.int8)\n",
    "\n",
    "    return torch.matmul(A_i8.to(torch.int16), B_i8.to(torch.int16)) / C_scale\n",
    "\n",
    "def matmul_i8(A: torch.Tensor, B: torch.Tensor, alpha = 5) -> torch.Tensor:\n",
    "    A_scale = 127 / torch.max(torch.abs(A))\n",
    "    B_scale = 127 / torch.max(torch.abs(B))\n",
    "    C_scale = A_scale * B_scale\n",
    "\n",
    "    A_i8 = (A  * A_scale).round().to(torch.int8)\n",
    "    B_i8 = (B  * B_scale).round().to(torch.int8)\n",
    "\n",
    "    return torch.matmul(A_i8.to(torch.int16), B_i8.to(torch.int16)) / C_scale\n",
    "\n",
    "def LLM_matmul_i8(X: torch.Tensor, W: torch.Tensor, alpha = 5) -> torch.Tensor:\n",
    "    X_col_filter = torch.max(torch.abs(X), dim = 0).values > alpha\n",
    "    X1 = X[:, X_col_filter]\n",
    "    W1 = W[X_col_filter, :]\n",
    "    X2 = X[:, ~X_col_filter]\n",
    "    W2 = W[~X_col_filter, :]\n",
    "    \n",
    "    C1 = torch.matmul(X1, W1)\n",
    "    print(f'Reserved {(X1.shape[1] / X.shape[1] * 100):.1f}%')\n",
    "    X2_scale = 127 / torch.max(torch.abs(X2), dim=1).values\n",
    "    W2_scale = 127 / torch.max(torch.abs(W2), dim=0).values\n",
    "    C2_scale = torch.matmul(X2_scale.unsqueeze(1), W2_scale.unsqueeze(0))\n",
    "\n",
    "    X2_i8 = (X2  * X2_scale.unsqueeze(1)).round().to(torch.int8)\n",
    "    W2_i8 = (W2  * W2_scale.unsqueeze(0)).round().to(torch.int8)\n",
    "\n",
    "    C2 = torch.matmul(X2_i8.to(torch.int16), W2_i8.to(torch.int16)) / C2_scale\n",
    "    \n",
    "    return C1 + C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reserved 33.0%\n",
      "tensor(8832., dtype=torch.bfloat16) tensor(3.5312, dtype=torch.bfloat16)\n",
      "tensor(12928., dtype=torch.bfloat16) tensor(5.1562, dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(50, 100, dtype=torch.bfloat16)\n",
    "W = torch.randn(100, 50, dtype=torch.bfloat16)\n",
    "X[0,0:X.shape[1] // 3] = 6\n",
    "\n",
    "error = torch.sum(torch.abs(LLM_matmul_i8(X, W) - X @ W))\n",
    "print(error, error/(X.shape[0] * W.shape[1]))\n",
    "# print(LLM_matmul_i8(X, W, 3) - X@W)\n",
    "\n",
    "error = torch.sum(torch.abs(matmul_vector_abs_i8(X, W) - X @ W))\n",
    "print(error, error/(X.shape[0] * W.shape[1]))\n",
    "# print(matmul_vector_abs_i8(X, W) - X@W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1733)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(5, 5)\n",
    "A_i8, A_recon = absmax_quantize_i8(A)\n",
    "torch.sum(torch.abs(A - A_recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0715)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_i8, A_recon = zeropoint_quantize_i8(A)\n",
    "torch.sum(torch.abs(A - A_recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0871)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_i8, A_recon = zeropoint_quantize(A)\n",
    "torch.sum(torch.abs(A - A_recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9214, dtype=torch.float16),\n",
       " tensor([[ 1.9531e-03, -3.5645e-02, -2.9297e-03,  3.8574e-02,  1.3477e-01],\n",
       "         [-6.4453e-02,  6.5918e-03,  7.2021e-03, -1.6992e-01,  4.5898e-02],\n",
       "         [-7.2266e-02,  3.5400e-03, -1.0681e-04,  3.1738e-02, -4.2480e-02],\n",
       "         [-5.1880e-04, -1.5625e-02, -4.8340e-02,  5.3711e-03,  3.6621e-03],\n",
       "         [-2.5146e-02,  3.0273e-02,  1.1963e-02,  1.2109e-01,  1.2817e-03]],\n",
       "        dtype=torch.float16))"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(5, 5).to(torch.float16)\n",
    "B = torch.randn(5, 5).to(torch.float16)\n",
    "\n",
    "nd_A_f16 = (255 / (A.max() - A.min())).round().to(A)\n",
    "nd_B_f16 = (255 / (B.max() - B.min())).round().to(A)\n",
    "zp_A_i16 = (A * A.min()).round().to(torch.int16)\n",
    "zp_B_i16 = (B * B.min()).round().to(torch.int16)\n",
    "\n",
    "A_i8 = (A * nd_A_f16).round().to(torch.int16)\n",
    "# print(A_i8 - (A * nd_A_f16).round().to(torch.int16))\n",
    "B_i8 = (B * nd_B_f16).round().to(torch.int16)\n",
    "\n",
    "C_i32 = (A_i8.to(torch.int32) + zp_A_i16) * (B_i8.to(torch.int32) + zp_B_i16)\n",
    "torch.sum(torch.abs(C_i32 / (nd_A_f16 * nd_B_f16) - A * B)), C_i32 / (nd_A_f16 * nd_B_f16) - A * B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wheels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
