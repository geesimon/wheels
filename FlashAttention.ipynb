{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0043, 0.0116, 0.0315, 0.0858, 0.2331, 0.6337])\n",
      "tensor([0.0043, 0.0116, 0.0315, 0.0858, 0.2331, 0.6337])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([1,2,3],dtype=torch.float32)\n",
    "b=torch.tensor([4,5,6],dtype=torch.float32)\n",
    "print(torch.softmax(torch.concat([a,b]), dim=0))\n",
    "\n",
    "\n",
    "m_a=torch.max(a)\n",
    "f_a = torch.exp(a - m_a)\n",
    "l_a = torch.sum(f_a)\n",
    "\n",
    "m_b=torch.max(b)\n",
    "f_b = torch.exp(b - m_b)\n",
    "l_b = torch.sum(f_b)\n",
    "\n",
    "m = torch.max(m_a,m_b)\n",
    "f = torch.concat([torch.exp(m_a - m) * f_a, torch.exp(m_b - m) * f_b])\n",
    "l = torch.sum(f)\n",
    "\n",
    "print(f / l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2205.14135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Q: (batch, seq_len, dim)\n",
    "    K: (batch, seq_len, dim)\n",
    "    V: (batch, seq_len, dim)\n",
    "    mask: (batch, seq_len, seq_len)\n",
    "    return: (batch, seq_len, dim)\n",
    "'''\n",
    "\n",
    "def flash_attention(Q, K, V, M = 100_000, dropout_p = 0, is_causal=False):\n",
    "    b, N, d = Q.shape\n",
    "    Bc = M // (4 * d)\n",
    "    Br = min(Bc,d)\n",
    "    O = torch.zeros_like(Q)\n",
    "    l = torch.zeros(b, N)\n",
    "    m = torch.ones(b, N) * -float('inf')\n",
    "    Tr = N // Br + (1 if N % Br != 0 else 0)\n",
    "    Tc = N // Bc + (1 if N % Bc != 0 else 0)\n",
    "\n",
    "    for b_i in range(b):\n",
    "        for j in range(Tc):\n",
    "            K_j = K[b_i,Bc * j:Bc * (j + 1)]\n",
    "            V_j = V[b_i,Bc * j:Bc * (j + 1)]\n",
    "            \n",
    "            for i in range(Tr):\n",
    "                Q_i = Q[b_i, Br * i:Br * (i + 1)]\n",
    "                O_i = O[b_i, Br * i:Br * (i + 1)]\n",
    "                l_i = l[b_i, Br * i:Br * (i + 1)]\n",
    "                m_i = m[b_i, Br * i:Br * (i + 1)]\n",
    "\n",
    "                S_ij = torch.matmul(Q_i, K_j.T) / torch.sqrt(torch.tensor(d))\n",
    "                m_ij = torch.max(S_ij, dim=1).values\n",
    "                P_ij = torch.exp(S_ij - m_ij.unsqueeze(1))\n",
    "                l_ij = torch.sum(P_ij, dim=1)                \n",
    "                m_i_new = torch.max(m_i, m_ij)\n",
    "                l_i_new = torch.exp(m_i - m_i_new) * l_i + torch.exp(m_ij - m_i_new) * l_ij\n",
    "                \n",
    "                O_i = torch.diag(1 / l_i_new) @ (torch.diag(l_i * torch.exp(m_i - m_i_new)) @ O_i\n",
    "                                                 + torch.diag(torch.exp(m_ij - m_i_new)) @ torch.matmul(P_ij, V_j))\n",
    "                \n",
    "                O[b_i, Br * i:Br * (i + 1)] = O_i\n",
    "                l[b_i, Br * i:Br * (i + 1)] = l_i_new\n",
    "                m[b_i, Br * i:Br * (i + 1)] = m_i_new\n",
    "               \n",
    "    return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1100, -0.1308, -0.1471, -0.2566, -0.2753, -0.0186, -0.0416,  0.2561,\n",
      "         0.2481,  0.2214, -0.1783, -0.2921, -0.0652, -0.0359,  0.1991, -0.0006,\n",
      "         0.0613, -0.0169, -0.0540,  0.2433,  0.2231, -0.1169, -0.3628, -0.0878,\n",
      "         0.1079, -0.2581, -0.0285, -0.1207,  0.0692, -0.1183])\n",
      "tensor([ 0.1100, -0.1308, -0.1471, -0.2566, -0.2753, -0.0186, -0.0416,  0.2561,\n",
      "         0.2481,  0.2214, -0.1783, -0.2921, -0.0652, -0.0359,  0.1991, -0.0006,\n",
      "         0.0613, -0.0169, -0.0540,  0.2433,  0.2231, -0.1169, -0.3628, -0.0878,\n",
      "         0.1079, -0.2581, -0.0285, -0.1207,  0.0692, -0.1183])\n",
      "True\n",
      "CPU times: user 8.22 ms, sys: 0 ns, total: 8.22 ms\n",
      "Wall time: 7.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# b, n, d = 16, 1024, 512\n",
    "b, n, d = 8, 128, 32\n",
    "\n",
    "q=torch.randn(b, n, d)\n",
    "k=torch.randn(b, n, d)\n",
    "v=torch.randn(b, n, d)\n",
    "\n",
    "f_a = flash_attention(q, k, v)\n",
    "a = torch.softmax(q @ k.transpose(1,2) / np.sqrt(d), dim=-1) @ v\n",
    "print(f_a[0][0][:30])\n",
    "print(a[0][0][:30])\n",
    "print(f_a.allclose(a, atol=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-fundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
